{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96ea8655",
   "metadata": {},
   "source": [
    "# Use knlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f120dcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to $y$tem path the parent directory\n",
    "import os\n",
    "import sys\n",
    "notebook_dir = os.path.abspath(os.path.dirname(''))\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, os.pardir))\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75c34b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(os.path.join(notebook_dir, '..','models','saved_model_knlm2'),'rb') as inputfile:\n",
    "    kn_lm2 = pickle.load(inputfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9abf231",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentences = ['हरेक [MASK] नेपामको संविधानक पालना गर्नुपर्छ ।' ,\n",
    "                    'म पुस्तकालयबाट थुलो किताब पढ्न चाहन्छ ।',\n",
    "                    'तर उस समयमा पनि स्वस्थ राजनैतिक वातावरनको अभावले गर्दा देश विकासतर्फ विशेष प्रगति हुन  सकेन।',\n",
    "                   'नेपालमा आधुनिक रुपमा आर्थक विकाससम्बन्धी कार्यरू प्रारम्भ भएको हालै मात्र हो।',\n",
    "                   'हार धुनुहोस् र स्वास्थ जीवन जिउनुहोस्।',\n",
    "                   'जब प्रवीधिहरू एकीकृत हुन सूरु गर्छन् अर्थतन्त्र तथ सँस्कृति पनि निश्चितरूपमा विस्तारै एकीकृत हुने छ।',\n",
    "                   'उद्देयहरुमा पनि कुनै एक उद्देश्य पूर्ति नहुँदै अर्को नयाँ  उद्देश्यको रुपमा लिइने परम्परा बस्यो।',\n",
    "                   'लगानीकर्ताहरूको धयान तुरुन्त फेरियो , व्यापारीहरुले वताए ।',\n",
    "                    'अति धेरै हिज्जे गलती भएका शब्दहरू । तपाईँले टाइप गर्दा हिज्जे जाँच अक्षम पारयो ।',\n",
    "                    'लामो',\n",
    "                    'म नेपाली राम्रोसँग बोल्दिन',\n",
    "                    'तपाईंको उमर कति हो?',\n",
    "                    'मलाइ एक्लै छोडनुहोस्',\n",
    "                   'रुसी राष्ट्रपती पुटिनको प्रेम जावन त्य्ती सफल छैन ।']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83703bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74da5e43",
   "metadata": {},
   "source": [
    "# Functions to correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef2b1a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import BrillMoore\n",
    "import regex as re\n",
    "from utils import final_candidate_words, return_lexicon_dict\n",
    "import math\n",
    "import itertools\n",
    "import numpy\n",
    "\n",
    "def words(text): \n",
    "    text = re.sub(r'[\\u0964]', r'\\u0020\\u0964\\u0020', text)\n",
    "    return re.findall(r'[\\u0900-\\u097F]+', text.lower())\n",
    "\n",
    "final_lexicon_dict = return_lexicon_dict()\n",
    "\n",
    "with open(os.path.join(notebook_dir, '..','models','bma_27dec.pickle'),'rb') as f:\n",
    "    bma = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac6de5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_bigram(text):   \n",
    "    text = re.sub(r'[\\u0964]', r'\\u0020\\u0964\\u0020', text)\n",
    "    return [tuple(x.split()) for x in re.findall\n",
    "                                (r'\\b[\\u0900-\\u097F]+\\s[\\u0900-\\u097F]+',text.lower(), overlapped=True)]\n",
    "\n",
    "\n",
    "def logprob(ngram,model,minimum):\n",
    "    '''\n",
    "    Calculate log probability\n",
    "    \n",
    "    \n",
    "    '''    \n",
    "    if ngram in model.lm[0]:\n",
    "        return model.lm[0][ngram]\n",
    "    return minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77e0f540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_bm(sentence,candidate_sentence):\n",
    "    '''\n",
    "    Returns P(Possible Typo Sentence/Candidate Correct Sentence)\n",
    "    \n",
    "    Uses Naive approach to compute probability for sentence from individual words\n",
    "    \n",
    "    '''    \n",
    "    \n",
    "    prod = 1\n",
    "    for word,candidate_word in zip(sentence.split(),candidate_sentence):          \n",
    "        prod*= bma.likelihood(word,candidate_word)\n",
    "        #print(\"prod:\",prod)\n",
    "    return prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76db903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctize_entire_knlm(sentence, model,p_lambda = 1,prior='bigram',trie = False,likelihood = 'default'):\n",
    "    \"Corrects the given 'sentence' using minimum edit\"\n",
    "\n",
    "    tokens = words(sentence)\n",
    "\n",
    "    candidates = []    \n",
    "    for _ in tokens:\n",
    "        candidates.append(final_candidate_words(_,use_trie = trie))\n",
    "    \n",
    "   \n",
    "    candidate_sentences = list(itertools.product(*candidates))\n",
    "    minimum = min(model.lm[0].values())\n",
    "    \n",
    "    if prior == 'trigram':\n",
    "        pass\n",
    "    \n",
    "    if prior == 'bigram':\n",
    "        bi_tokens = [words_bigram(' '.join(_)) for _ in candidate_sentences]\n",
    "        bi_token_probab = []\n",
    "   \n",
    "        for row in bi_tokens:\n",
    "            bi_token_probab.append([logprob(tuple(_),model,minimum) for _ in row])  \n",
    "\n",
    "        if likelihood=='default':\n",
    "            candidate_count = [len(_) for _ in candidates]  \n",
    "            sentences_probab_post=[(sum(row)*p_lambda) +\n",
    "                                   math.log(constant_distributive_likelihood(sentence,candidate_sentence,candidate_count)) \n",
    "                                   for row,candidate_sentence in zip(bi_token_probab,candidate_sentences)]\n",
    "        elif likelihood=='bm':\n",
    "            sentences_probab_post=[(sum(row)*p_lambda) + \n",
    "                                    math.log(likelihood_bm(sentence,candidate_sentence)) \n",
    "                                    for row,candidate_sentence in zip(bi_token_probab,candidate_sentences)]\n",
    "\n",
    "\n",
    "        \n",
    "        sorted_index = numpy.argsort(sentences_probab_post)\n",
    "        sentences_probab_post_sorted = sorted(sentences_probab_post,reverse = True)\n",
    "        \n",
    "        return [candidate_sentences[k] for k in sorted_index[::-1]],sentences_probab_post_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a4d5b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctize_with_window_knlm(sentence,model,window = 5,p_lambda = 1,prior = 'bigram',trie = False,likelihood = 'default'):\n",
    "    '''\n",
    "    \n",
    "    '''   \n",
    "    \n",
    "    tokens = words(sentence)\n",
    "    if len(tokens) <= window:\n",
    "        return [correctize_entire_knlm(sentence,model,p_lambda=p_lambda,prior = prior,trie = trie,likelihood = likelihood)]\n",
    "    else:\n",
    "        windows = [tokens[n:window+n] for n in range(0,len(tokens),window-1) if window+n <len(tokens)-1]    \n",
    "        remaining = (window-1)*len(windows)\n",
    "        windows.append(tokens[remaining:])\n",
    "        corrects = []\n",
    "        for _ in windows:\n",
    "            d = correctize_entire_knlm(' '.join(_),model,p_lambda=p_lambda,prior = prior,trie = trie,likelihood = likelihood)\n",
    "            corrects.append(d)\n",
    "        return corrects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a195b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_choices2(sample_sentences,model,p_lambda = 1,trie = False,model_type ='knlm' ,likelihood = 'default'):\n",
    "    \n",
    "    if model_type =='knlm':\n",
    "        d = correctize_with_window_knlm(sample_sentences,model,p_lambda =p_lambda,trie = trie,likelihood = likelihood)\n",
    "        window_candidates = []\n",
    "        window_probab = []\n",
    "        for window in d:\n",
    "            maxim = min(len(window[0]),10)\n",
    "            top_candidates = window[0][:maxim]\n",
    "            window_candidates.append(top_candidates)\n",
    "            window_probab.append(window[1][:maxim])\n",
    "        return window_candidates,window_probab\n",
    "    \n",
    "    if model_type == 'transformer':\n",
    "        d = correctize_with_window_nn(sample_sentences,model,p_lambda =p_lambda,trie = trie,likelihood = likelihood)\n",
    "        window_candidates = []\n",
    "        window_probab = []\n",
    "        for window in d:\n",
    "            maxim = min(len(window[0]),10)\n",
    "            top_candidates = window[0][:maxim]\n",
    "            window_candidates.append(top_candidates)\n",
    "            window_probab.append(window[1][:maxim])\n",
    "        return window_candidates,window_probab\n",
    "        \n",
    "def extract_choices(sample_sentences,model,p_lambda = 1,trie = False,likelihood = 'default',model_type = 'knlm'):\n",
    "    \n",
    "    \n",
    "    wc,wp = return_choices2(sample_sentences,model,p_lambda = p_lambda,trie = trie ,model_type = model_type,likelihood = likelihood)\n",
    "#     choices_list=[set() for i in range(len(sample_sentences.split())+1)]\n",
    "    choices_list=[[] for i in range(len(sample_sentences.split())+1)]\n",
    "#     print(len(choices_list))\n",
    "\n",
    "    const = 0\n",
    "    for _ in wc:\n",
    "        for sens in _:\n",
    "            for i,w in enumerate(sens):\n",
    "                index = i + const\n",
    "                if w not in choices_list[index]:\n",
    "                    choices_list[index].append(w)\n",
    "        const += len(wc[0][0])-1\n",
    "    if len(choices_list[len(choices_list)-1]) == 0:\n",
    "        return choices_list[:len(choices_list)-1]\n",
    "    return choices_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac39adac",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3711de2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['म', 'क', 'मा', 'त', 'मि'],\n",
       " ['पुस्तकालयबाट'],\n",
       " ['थुलो', 'थलो', 'धुलो'],\n",
       " ['किताब'],\n",
       " ['पढ्न', 'पस्न', 'पर्न', 'बढ्न', 'पढ्ने', 'चढ्न'],\n",
       " ['चाहन्छ', 'चाहिन्छ', 'चाहन्छु', 'चाहन्छन्'],\n",
       " ['।']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_choices(sample_sentences[1],model=kn_lm2,p_lambda = 0.,trie = True,likelihood = 'bm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69513252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['पर', 'तर', 'तह', 'गर'],\n",
       " ['स', 'उप', 'उसो', 'आस'],\n",
       " ['समयमा', 'समयको', 'समयका'],\n",
       " ['पनि'],\n",
       " ['स्वस्थ', 'अस्वस्थ', 'स्वच्छ'],\n",
       " ['राजनीतिक', 'राजनैतिक', 'राजनीति'],\n",
       " ['वातावरणको'],\n",
       " ['अभावले', 'अभावमा'],\n",
       " ['गर्दा', 'गर्न', 'गर्दै', 'पर्दा'],\n",
       " ['देश'],\n",
       " ['विकासतर्फ'],\n",
       " ['विशेष'],\n",
       " ['प्रगति', 'प्रति', 'प्रालि', 'प्रगतिको', 'प्रावि', 'प्रगाढ'],\n",
       " ['हुन', 'हुने', 'हुनै'],\n",
       " ['सकेन', 'सकेनन्', 'सकेका', 'सकिन', 'सक्न', 'सकेमा', 'सकेर'],\n",
       " ['।']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_choices(sample_sentences[2],model=kn_lm2,p_lambda = 0.8,trie = True,likelihood = 'bm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0ece0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'तर उस समयमा पनि स्वस्थ राजनैतिक वातावरनको अभावले गर्दा देश विकासतर्फ विशेष प्रगति हुन  सकेन।'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentences[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bad0b2",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a1d2a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval import gather_dataset,WER,word_accuracy,char_accuracy\n",
    "\n",
    "dataset_file = os.path.join(notebook_dir, '..','data','eval_data2.pic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62c6d8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = gather_dataset(dataset_file)[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "803da8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_tokens = [words(t[0]) for t in dataset]\n",
    "error_tokens = [words(t[1]) for t in dataset]\n",
    "error_sentences = [t[1] for t in dataset] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461aeeb2",
   "metadata": {},
   "source": [
    "### Bm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e139fab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gap = 0.2\n",
    "a = 10\n",
    "def find_p_lambda(error_sentences):\n",
    "    predicted_tokens = []\n",
    "    for j in range(10):\n",
    "        for i,s in enumerate(error_sentences[:a]):\n",
    "            c = extract_choices(s,model=kn_lm2,p_lambda =Gap*j,trie = True,likelihood = 'bm')\n",
    "        #     print(c)\n",
    "            c = [t[0] for t in c]\n",
    "            predicted_tokens.append(c)\n",
    "            if i%2 == 0:\n",
    "                print(i)\n",
    "#         word_accuracy(correct_tokens[:a],predicted_tokens[:a],error_tokens[:a])\n",
    "        print(Gap*j,' : ',word_accuracy(correct_tokens[:a],predicted_tokens[:a],error_tokens[:a]),'WER1: ',WER(correct_tokens[:a],error_tokens[:a] ),'WER2: ',WER(correct_tokens[:a],predicted_tokens[:a] ))\n",
    "find_p_lambda(error_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "932de56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "0.0  :  (0.0, 0, 42) WER1:  0.2727272727272727 WER2:  0.2727272727272727\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "0.2  :  (0.0, 0, 42) WER1:  0.2727272727272727 WER2:  0.2727272727272727\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "0.4  :  (0.0, 0, 42) WER1:  0.2727272727272727 WER2:  0.2727272727272727\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "0.6000000000000001  :  (0.0, 0, 42) WER1:  0.2727272727272727 WER2:  0.2727272727272727\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "0.8  :  (0.0, 0, 42) WER1:  0.2727272727272727 WER2:  0.2727272727272727\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "1.0  :  (0.0, 0, 42) WER1:  0.2727272727272727 WER2:  0.2727272727272727\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "1.2000000000000002  :  (0.0, 0, 42) WER1:  0.2727272727272727 WER2:  0.2727272727272727\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "1.4000000000000001  :  (0.0, 0, 42) WER1:  0.2727272727272727 WER2:  0.2727272727272727\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "1.6  :  (0.0, 0, 42) WER1:  0.2727272727272727 WER2:  0.2727272727272727\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "1.8  :  (0.0, 0, 42) WER1:  0.2727272727272727 WER2:  0.2727272727272727\n"
     ]
    }
   ],
   "source": [
    "Gap = 0.2\n",
    "a = 10\n",
    "def find_p_lambda(error_sentences):\n",
    "    predicted_tokens = []\n",
    "    for j in range(10):\n",
    "        for i,s in enumerate(error_sentences[:a]):\n",
    "            c = extract_choices(s,model=kn_lm2,p_lambda =Gap*j,trie = True,likelihood = 'bm')\n",
    "        #     print(c)\n",
    "            c = [t[0] for t in c]\n",
    "            predicted_tokens.append(c)\n",
    "            if i%2 == 0:\n",
    "                print(i)\n",
    "#         word_accuracy(correct_tokens[:a],predicted_tokens[:a],error_tokens[:a])\n",
    "        print(Gap*j,' : ',word_accuracy(correct_tokens[:a],predicted_tokens[:a],error_tokens[:a]),'WER1: ',WER(correct_tokens[:a],error_tokens[:a] ),'WER2: ',WER(correct_tokens[:a],predicted_tokens[:a] ))\n",
    "find_p_lambda(error_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16bcdfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "16\n",
      "18\n",
      "20\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "30\n",
      "32\n",
      "34\n",
      "36\n",
      "38\n",
      "40\n",
      "42\n",
      "44\n",
      "46\n",
      "48\n",
      "50\n",
      "52\n",
      "54\n",
      "56\n",
      "58\n",
      "60\n",
      "62\n",
      "64\n",
      "66\n",
      "68\n",
      "70\n",
      "72\n",
      "74\n",
      "76\n",
      "78\n",
      "80\n",
      "82\n",
      "84\n",
      "86\n",
      "88\n",
      "90\n",
      "92\n",
      "94\n",
      "96\n",
      "98\n",
      "100\n",
      "102\n",
      "104\n",
      "106\n",
      "108\n",
      "110\n",
      "112\n",
      "114\n",
      "116\n",
      "118\n",
      "120\n",
      "122\n",
      "124\n",
      "126\n",
      "128\n",
      "130\n",
      "132\n",
      "134\n",
      "136\n",
      "138\n",
      "140\n",
      "142\n",
      "144\n",
      "146\n",
      "148\n",
      "150\n",
      "152\n",
      "154\n",
      "156\n",
      "158\n",
      "160\n",
      "162\n",
      "164\n",
      "166\n",
      "168\n",
      "170\n",
      "172\n",
      "174\n",
      "176\n",
      "178\n",
      "180\n",
      "182\n",
      "184\n",
      "186\n",
      "188\n",
      "190\n",
      "192\n",
      "194\n",
      "196\n",
      "198\n",
      "200\n",
      "202\n",
      "204\n",
      "206\n",
      "208\n",
      "210\n",
      "212\n",
      "214\n",
      "216\n",
      "218\n",
      "220\n",
      "222\n",
      "224\n",
      "226\n",
      "228\n",
      "230\n",
      "232\n",
      "234\n",
      "236\n",
      "238\n",
      "240\n",
      "242\n",
      "244\n",
      "246\n",
      "248\n",
      "250\n",
      "252\n",
      "254\n",
      "256\n",
      "258\n",
      "260\n",
      "262\n",
      "264\n",
      "266\n",
      "268\n",
      "270\n",
      "272\n",
      "274\n",
      "276\n",
      "278\n",
      "280\n",
      "282\n",
      "284\n",
      "286\n",
      "288\n",
      "290\n",
      "292\n",
      "294\n",
      "296\n",
      "298\n",
      "300\n",
      "302\n",
      "304\n",
      "306\n",
      "308\n",
      "310\n",
      "312\n",
      "314\n",
      "316\n",
      "318\n",
      "320\n",
      "322\n",
      "0.25042111173498033 0.18697361033127458 (0.6472346786248132, 866, 1338) (0.682741116751269, 1076, 1576)\n",
      "324\n",
      "326\n",
      "328\n",
      "330\n",
      "332\n",
      "334\n",
      "336\n",
      "338\n",
      "340\n",
      "342\n",
      "344\n",
      "346\n",
      "348\n",
      "350\n",
      "352\n",
      "354\n",
      "356\n",
      "358\n",
      "360\n",
      "362\n",
      "364\n",
      "366\n",
      "368\n",
      "370\n",
      "372\n",
      "374\n",
      "376\n",
      "378\n",
      "380\n",
      "382\n",
      "384\n",
      "386\n",
      "388\n",
      "390\n",
      "392\n",
      "394\n",
      "396\n",
      "398\n"
     ]
    }
   ],
   "source": [
    "predicted_tokens = []\n",
    "for i,s in enumerate(error_sentences):\n",
    "    c = extract_choices(s,model=kn_lm2,p_lambda =0.8 ,trie = True,likelihood = 'bm')\n",
    "#     print(c)\n",
    "    c = [t[0] for t in c]\n",
    "    predicted_tokens.append(c)\n",
    "    if i%2 == 0:\n",
    "        print(i)\n",
    "    if i==323:\n",
    "        l = len(predicted_tokens)\n",
    "        print(WER(correct_tokens[:l],error_tokens[:l] ),WER(correct_tokens[:l],predicted_tokens[:l] ),word_accuracy(correct_tokens[:l],predicted_tokens[:l],error_tokens[:l]),char_accuracy(correct_tokens[:l],predicted_tokens[:l],error_tokens[:l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7df7b95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.25042111173498033, 0.18697361033127458)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = len(predicted_tokens)\n",
    "WER(correct_tokens[:l],error_tokens[:a] ),WER(correct_tokens[:a],predicted_tokens[:a] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e23fe6cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6472346786248132, 866, 1338)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_accuracy(correct_tokens[:a],predicted_tokens[:a],error_tokens[:a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94f9237b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6706852791878173, 1057, 1576)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_accuracy(correct_tokens[:a],predicted_tokens[:a],error_tokens[:a])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105314b7",
   "metadata": {},
   "source": [
    "### Constant Distributive likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b04ef987",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.65\n",
    "def constant_distributive_likelihood(sentence,candidate_sentence,candidate_count):\n",
    "    prod = 1    \n",
    "    i = 0\n",
    "    #print(sentence.split(),candidate_sentence)\n",
    "    \n",
    "    for word,candidate_word in zip(sentence.split(),candidate_sentence):        \n",
    "        if word==candidate_word:\n",
    "            prod*= alpha\n",
    "        else:\n",
    "            N = candidate_count[i]\n",
    "            prod*= (1-alpha)/N\n",
    "        i+=1\n",
    "    return prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "157513e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "0.0  :  (0.0, 0, 42) WER1:  0.2727272727272727 WER2:  0.2727272727272727\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "0.2  :  (0.0, 0, 42) WER1:  0.2727272727272727 WER2:  0.2727272727272727\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "0.4  :  (0.0, 0, 42) WER1:  0.2727272727272727 WER2:  0.2727272727272727\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "0.6000000000000001  :  (0.0, 0, 42) WER1:  0.2727272727272727 WER2:  0.2727272727272727\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "0.8  :  (0.0, 0, 42) WER1:  0.2727272727272727 WER2:  0.2727272727272727\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "1.0  :  (0.0, 0, 42) WER1:  0.2727272727272727 WER2:  0.2727272727272727\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "1.2000000000000002  :  (0.0, 0, 42) WER1:  0.2727272727272727 WER2:  0.2727272727272727\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "1.4000000000000001  :  (0.0, 0, 42) WER1:  0.2727272727272727 WER2:  0.2727272727272727\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "1.6  :  (0.0, 0, 42) WER1:  0.2727272727272727 WER2:  0.2727272727272727\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "1.8  :  (0.0, 0, 42) WER1:  0.2727272727272727 WER2:  0.2727272727272727\n"
     ]
    }
   ],
   "source": [
    "Gap = 0.2\n",
    "a = 10\n",
    "def find_p_lambda(error_sentences):\n",
    "    predicted_tokens = []\n",
    "    for j in range(10):\n",
    "        for i,s in enumerate(error_sentences[:a]):\n",
    "            c = extract_choices(s,model=kn_lm2,p_lambda =Gap*j,trie = True,likelihood = 'default')\n",
    "        #     print(c)\n",
    "            c = [t[0] for t in c]\n",
    "            predicted_tokens.append(c)\n",
    "            if i%2 == 0:\n",
    "                print(i)\n",
    "#         word_accuracy(correct_tokens[:a],predicted_tokens[:a],error_tokens[:a])\n",
    "        print(Gap*j,' : ',word_accuracy(correct_tokens[:a],predicted_tokens[:a],error_tokens[:a]),'WER1: ',WER(correct_tokens[:a],error_tokens[:a] ),'WER2: ',WER(correct_tokens[:a],predicted_tokens[:a] ))\n",
    "find_p_lambda(error_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a98d380f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "16\n",
      "18\n",
      "20\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "30\n",
      "32\n",
      "34\n",
      "36\n",
      "38\n",
      "40\n",
      "42\n",
      "44\n",
      "46\n",
      "48\n",
      "50\n",
      "52\n",
      "54\n",
      "56\n",
      "58\n",
      "60\n",
      "62\n",
      "64\n",
      "66\n",
      "68\n",
      "70\n",
      "72\n",
      "74\n",
      "76\n",
      "78\n",
      "80\n",
      "82\n",
      "84\n",
      "86\n",
      "88\n",
      "90\n",
      "92\n",
      "94\n",
      "96\n",
      "98\n",
      "100\n",
      "102\n",
      "104\n",
      "106\n",
      "108\n",
      "110\n",
      "112\n",
      "114\n",
      "116\n",
      "118\n",
      "120\n",
      "122\n",
      "124\n",
      "126\n",
      "128\n",
      "130\n",
      "132\n",
      "134\n",
      "136\n",
      "138\n",
      "140\n",
      "142\n",
      "144\n",
      "146\n",
      "148\n",
      "150\n",
      "152\n",
      "154\n",
      "156\n",
      "158\n",
      "160\n",
      "162\n",
      "164\n",
      "166\n",
      "168\n",
      "170\n",
      "172\n",
      "174\n",
      "176\n",
      "178\n",
      "180\n",
      "182\n",
      "184\n",
      "186\n",
      "188\n",
      "190\n",
      "192\n",
      "194\n",
      "196\n",
      "198\n",
      "200\n",
      "202\n",
      "204\n",
      "206\n",
      "208\n",
      "210\n",
      "212\n",
      "214\n",
      "216\n",
      "218\n",
      "220\n",
      "222\n",
      "224\n",
      "226\n",
      "228\n",
      "230\n",
      "232\n",
      "234\n",
      "236\n",
      "238\n",
      "240\n",
      "242\n",
      "244\n",
      "246\n",
      "248\n",
      "250\n",
      "252\n",
      "254\n",
      "256\n",
      "258\n",
      "260\n",
      "262\n",
      "264\n",
      "266\n",
      "268\n",
      "270\n",
      "272\n",
      "274\n",
      "276\n",
      "278\n",
      "280\n",
      "282\n",
      "284\n",
      "286\n",
      "288\n",
      "290\n",
      "292\n",
      "294\n",
      "296\n",
      "298\n",
      "300\n",
      "302\n",
      "304\n",
      "306\n",
      "308\n",
      "310\n",
      "312\n",
      "314\n",
      "316\n",
      "318\n",
      "320\n",
      "322\n",
      "324\n",
      "326\n",
      "328\n",
      "330\n",
      "332\n",
      "334\n",
      "336\n",
      "338\n",
      "340\n",
      "342\n",
      "344\n",
      "346\n",
      "348\n",
      "350\n",
      "352\n",
      "354\n",
      "356\n",
      "358\n",
      "360\n",
      "362\n",
      "364\n",
      "366\n",
      "368\n",
      "370\n",
      "372\n",
      "374\n",
      "376\n",
      "378\n",
      "380\n",
      "382\n",
      "384\n",
      "386\n",
      "388\n",
      "390\n",
      "392\n",
      "394\n",
      "396\n",
      "398\n"
     ]
    }
   ],
   "source": [
    "predicted_tokens = []\n",
    "for i,s in enumerate(error_sentences):\n",
    "    c = extract_choices(s,model=kn_lm2,p_lambda =0.8 ,trie = True,likelihood = 'default')\n",
    "#     print(c)\n",
    "    c = [t[0] for t in c]\n",
    "    predicted_tokens.append(c)\n",
    "    if i%2 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "790daafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.25042111173498033, 0.20082350739285046)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 324\n",
    "WER(correct_tokens[:a],error_tokens[:a] ),WER(correct_tokens[:a],predicted_tokens[:a] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4658f390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.601644245142003, 805, 1338)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_accuracy(correct_tokens[:a],predicted_tokens[:a],error_tokens[:a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14bd0295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6706852791878173, 1057, 1576)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_accuracy(correct_tokens[:a],predicted_tokens[:a],error_tokens[:a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8892c813",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
