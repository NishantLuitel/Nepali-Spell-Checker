{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e495f031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated git hooks.\n",
      "Git LFS initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'NepaliBERT' already exists and is not an empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in f:\\spellchecker\\venv\\lib\\site-packages (4.36.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in f:\\spellchecker\\venv\\lib\\site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in f:\\spellchecker\\venv\\lib\\site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: packaging>=20.0 in f:\\spellchecker\\venv\\lib\\site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: filelock in f:\\spellchecker\\venv\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in f:\\spellchecker\\venv\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in f:\\spellchecker\\venv\\lib\\site-packages (from transformers) (2022.4.24)\n",
      "Requirement already satisfied: requests in f:\\spellchecker\\venv\\lib\\site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in f:\\spellchecker\\venv\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.17 in f:\\spellchecker\\venv\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in f:\\spellchecker\\venv\\lib\\site-packages (from transformers) (0.20.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in f:\\spellchecker\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.4.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in f:\\spellchecker\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\n",
      "Requirement already satisfied: colorama in f:\\spellchecker\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in f:\\spellchecker\\venv\\lib\\site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in f:\\spellchecker\\venv\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in f:\\spellchecker\\venv\\lib\\site-packages (from requests->transformers) (3.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\spellchecker\\venv\\lib\\site-packages (from requests->transformers) (2022.12.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# #Run for first time\n",
    "# !git lfs install\n",
    "# !git clone https://huggingface.co/Rajan/NepaliBERT\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ea8655",
   "metadata": {},
   "source": [
    "# Use NepBert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def64a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "201836d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to $y$tem path the parent directory\n",
    "import os\n",
    "import sys\n",
    "notebook_dir = os.path.abspath(os.path.dirname(''))\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, os.pardir))\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43503ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbc68055",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "vocab_file_dir = './NepaliBERT/' \n",
    "tokenizer = BertTokenizer.from_pretrained(vocab_file_dir,\n",
    "                                        strip_accents=False,\n",
    "                                         clean_text=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d957ac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForMaskedLM\n",
    "model = BertForMaskedLM.from_pretrained('./NepaliBERT').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3fd66aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "fill_mask = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f7ff630",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#help(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27f2c23",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9abf231",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentences = ['हरेक [MASK] नेपामको संविधानक पालना गर्नुपर्छ ।' ,\n",
    "                    'म पुस्तकालयबाट थुलो किताब पढ्न चाहन्छ ।',\n",
    "                    'तर उस समयमा पनि स्वस्थ राजनैतिक वातावरनको अभावले गर्दा देश विकासतर्फ विशेष प्रगति हुन  सकेन।',\n",
    "                   'नेपालमा आधुनिक रुपमा आर्थक विकाससम्बन्धी कार्यरू प्रारम्भ भएको हालै मात्र हो।',\n",
    "                   'हार धुनुहोस् र स्वास्थ जीवन जिउनुहोस्।',\n",
    "                   'जब प्रवीधिहरू एकीकृत हुन सूरु गर्छन् अर्थतन्त्र तथ सँस्कृति पनि निश्चितरूपमा विस्तारै एकीकृत हुने छ।',\n",
    "                   'उद्देयहरुमा पनि कुनै एक उद्देश्य पूर्ति नहुँदै अर्को नयाँ  उद्देश्यको रुपमा लिइने परम्परा बस्यो।',\n",
    "                   'लगानीकर्ताहरूको धयान तुरुन्त फेरियो , व्यापारीहरुले वताए ।',\n",
    "                    'अति धेरै हिज्जे गलती भएका शब्दहरू । तपाईँले टाइप गर्दा हिज्जे जाँच अक्षम पारयो ।',\n",
    "                    'लामो',\n",
    "                    'म नेपाली राम्रोसँग बोल्दिन',\n",
    "                    'तपाईंको उमर कति हो?',\n",
    "                    'मलाइ एक्लै छोडनुहोस्',\n",
    "                   'रुसी राष्ट्रपती पुटिनको प्रेम जावन त्य्ती सफल छैन ।']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83703bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da4ca56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 126, 9538, 600, 4622, 619, 4534, 3907, 4636, 163, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tokenizer(sample_sentences[1])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed1a0952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'प ु स ् त क ा ल य'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(9538)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6c1c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb13eaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tokenizer(sample_sentences,padding = 'max_length',max_length =max_length,truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5855e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = t['input_ids']\n",
    "mask = t['attention_mask']\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "\n",
    "input_ids = torch.tensor(ids)\n",
    "mask_ids = torch.tensor(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27afe626",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    2,  1909,     4, 34654,  3685,  1294,   321,  6048,  2141,   163,\n",
       "              3,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0],\n",
       "         [    2,   126,  9538,   600,  4622,   619,  4534,  3907,  4636,   163,\n",
       "              3,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0],\n",
       "         [    2,   688,  5682,  1782,   557,  5501, 14940, 31959,   310,  2343,\n",
       "            888,  7473,  1157,  1008, 40448,  1481,  3874,   880,  2250,   163,\n",
       "              3,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0],\n",
       "         [    2,  1521,  4102,   963,  1162,   321, 39485,   636, 24118,  3715,\n",
       "            611,  4415,   771,   589,   163,     3,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0],\n",
       "         [    2,  2453, 10976,   312,  3509,   128, 14276,  1841, 26216,   312,\n",
       "           3509,   163,     3,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0],\n",
       "         [    2,  2425,  1273,   323,   821,   607,  4623,   880,  1508,   797,\n",
       "           1810,  3293,  1935, 10611, 13837,   557,  3654,  5667,  6813,  4623,\n",
       "            685,   108,   163,     3,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0],\n",
       "         [    2,  1899,  3228,   320,  2575,   557,   742,   656,  2868, 13649,\n",
       "          13164,  1367,   848,  2868,   518,   963, 15679,  4225, 13414,   163,\n",
       "              3,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0],\n",
       "         [    2, 39993,   120,  4545,  7240, 22827,     1, 37521, 19514,   163,\n",
       "              3,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0],\n",
       "         [    2,  2272,   929, 42640, 36889,   316,  3244,   323,   729, 23200,\n",
       "            163, 19429, 22160,  1157, 42640, 36889,   316,  4126, 30400,  1076,\n",
       "            575,   163,     3,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0],\n",
       "         [    2,  1836,     3,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0],\n",
       "         [    2,   126,   917,  7324,  5461,  2259,     3,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0],\n",
       "         [    2,  6641,  6111,   313,  1347,   589,     1,     3,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0],\n",
       "         [    2, 22047,  6338,  3493, 36434,     3,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0],\n",
       "         [    2, 14805,  1177, 24506, 42364,  2383, 11887,   324,   595, 21960,\n",
       "            323,  1640,   699,   163,     3,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0]]),\n",
       " torch.Size([14, 64]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids,input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e071788a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adc3d30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 126, 9538, 600, 4622, 619, 4534, 3907, 4636, 163, 3]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(sample_sentences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f805bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = model(input_ids.to(device),mask_ids.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b17fa47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2,\n",
       "  1909,\n",
       "  4,\n",
       "  34654,\n",
       "  3685,\n",
       "  1294,\n",
       "  321,\n",
       "  6048,\n",
       "  2141,\n",
       "  163,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [2,\n",
       "  126,\n",
       "  9538,\n",
       "  600,\n",
       "  4622,\n",
       "  619,\n",
       "  4534,\n",
       "  3907,\n",
       "  4636,\n",
       "  163,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [2,\n",
       "  688,\n",
       "  5682,\n",
       "  1782,\n",
       "  557,\n",
       "  5501,\n",
       "  14940,\n",
       "  31959,\n",
       "  310,\n",
       "  2343,\n",
       "  888,\n",
       "  7473,\n",
       "  1157,\n",
       "  1008,\n",
       "  40448,\n",
       "  1481,\n",
       "  3874,\n",
       "  880,\n",
       "  2250,\n",
       "  163,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [2,\n",
       "  1521,\n",
       "  4102,\n",
       "  963,\n",
       "  1162,\n",
       "  321,\n",
       "  39485,\n",
       "  636,\n",
       "  24118,\n",
       "  3715,\n",
       "  611,\n",
       "  4415,\n",
       "  771,\n",
       "  589,\n",
       "  163,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [2,\n",
       "  2453,\n",
       "  10976,\n",
       "  312,\n",
       "  3509,\n",
       "  128,\n",
       "  14276,\n",
       "  1841,\n",
       "  26216,\n",
       "  312,\n",
       "  3509,\n",
       "  163,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [2,\n",
       "  2425,\n",
       "  1273,\n",
       "  323,\n",
       "  821,\n",
       "  607,\n",
       "  4623,\n",
       "  880,\n",
       "  1508,\n",
       "  797,\n",
       "  1810,\n",
       "  3293,\n",
       "  1935,\n",
       "  10611,\n",
       "  13837,\n",
       "  557,\n",
       "  3654,\n",
       "  5667,\n",
       "  6813,\n",
       "  4623,\n",
       "  685,\n",
       "  108,\n",
       "  163,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [2,\n",
       "  1899,\n",
       "  3228,\n",
       "  320,\n",
       "  2575,\n",
       "  557,\n",
       "  742,\n",
       "  656,\n",
       "  2868,\n",
       "  13649,\n",
       "  13164,\n",
       "  1367,\n",
       "  848,\n",
       "  2868,\n",
       "  518,\n",
       "  963,\n",
       "  15679,\n",
       "  4225,\n",
       "  13414,\n",
       "  163,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [2,\n",
       "  39993,\n",
       "  120,\n",
       "  4545,\n",
       "  7240,\n",
       "  22827,\n",
       "  1,\n",
       "  37521,\n",
       "  19514,\n",
       "  163,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [2,\n",
       "  2272,\n",
       "  929,\n",
       "  42640,\n",
       "  36889,\n",
       "  316,\n",
       "  3244,\n",
       "  323,\n",
       "  729,\n",
       "  23200,\n",
       "  163,\n",
       "  19429,\n",
       "  22160,\n",
       "  1157,\n",
       "  42640,\n",
       "  36889,\n",
       "  316,\n",
       "  4126,\n",
       "  30400,\n",
       "  1076,\n",
       "  575,\n",
       "  163,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [2,\n",
       "  1836,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [2,\n",
       "  126,\n",
       "  917,\n",
       "  7324,\n",
       "  5461,\n",
       "  2259,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [2,\n",
       "  6641,\n",
       "  6111,\n",
       "  313,\n",
       "  1347,\n",
       "  589,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [2,\n",
       "  22047,\n",
       "  6338,\n",
       "  3493,\n",
       "  36434,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [2,\n",
       "  14805,\n",
       "  1177,\n",
       "  24506,\n",
       "  42364,\n",
       "  2383,\n",
       "  11887,\n",
       "  324,\n",
       "  595,\n",
       "  21960,\n",
       "  323,\n",
       "  1640,\n",
       "  699,\n",
       "  163,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a386618",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = torch.nn.LogSoftmax(dim = 2)\n",
    "# f = ls(v.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17b46c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.4231e+00, -2.5424e-03, -1.3525e+01, -1.7025e-01, -2.7737e-03,\n",
       "         -8.5081e-02, -2.8930e+00, -1.9277e-03, -1.7764e-03, -7.5102e-06,\n",
       "         -6.4597e+00, -1.9890e+01, -1.9577e+01, -1.9099e+01, -1.9004e+01,\n",
       "         -1.9502e+01, -1.9159e+01, -1.9449e+01, -1.9208e+01, -1.9487e+01,\n",
       "         -1.9848e+01, -1.9766e+01, -1.9482e+01, -1.9291e+01, -1.9714e+01,\n",
       "         -1.9686e+01, -1.9809e+01, -2.0063e+01, -1.9529e+01, -1.9244e+01,\n",
       "         -1.9632e+01, -1.9619e+01, -1.9810e+01, -2.0467e+01, -2.0178e+01,\n",
       "         -1.9932e+01, -2.1677e+01, -1.9791e+01, -1.9139e+01, -1.9575e+01,\n",
       "         -1.9524e+01, -1.9283e+01, -1.9593e+01, -1.9684e+01, -1.9980e+01,\n",
       "         -2.0379e+01, -1.9975e+01, -2.6268e+01, -2.0648e+01, -1.9679e+01,\n",
       "         -1.9538e+01, -1.9053e+01, -1.9899e+01, -1.8803e+01, -1.8870e+01,\n",
       "         -1.8950e+01, -1.9200e+01, -1.9063e+01, -1.9097e+01, -1.8958e+01,\n",
       "         -1.9803e+01, -1.9147e+01, -1.9711e+01, -1.9533e+01],\n",
       "        [-8.9505e+00, -7.1464e-04, -2.3362e-02, -5.3881e-05, -9.4423e-03,\n",
       "         -4.0220e-03, -6.0479e-03, -1.2984e-03, -3.8084e-03, -1.2040e-05,\n",
       "         -9.6045e+00, -1.8703e+01, -1.8399e+01, -1.8059e+01, -1.8071e+01,\n",
       "         -1.7826e+01, -1.7909e+01, -1.7572e+01, -1.8625e+01, -1.8307e+01,\n",
       "         -1.8297e+01, -1.8414e+01, -1.8143e+01, -1.8289e+01, -1.7841e+01,\n",
       "         -1.9010e+01, -1.9772e+01, -1.8900e+01, -1.7972e+01, -1.8717e+01,\n",
       "         -1.9376e+01, -1.8186e+01, -1.7669e+01, -2.0915e+01, -2.3747e+01,\n",
       "         -1.9806e+01, -2.0814e+01, -1.8911e+01, -1.8089e+01, -1.7328e+01,\n",
       "         -1.8057e+01, -1.7527e+01, -1.7983e+01, -1.7560e+01, -1.9104e+01,\n",
       "         -1.8124e+01, -1.7537e+01, -2.0731e+01, -1.9943e+01, -1.8972e+01,\n",
       "         -1.8953e+01, -1.9290e+01, -1.9179e+01, -1.7492e+01, -1.7929e+01,\n",
       "         -1.7399e+01, -1.8292e+01, -1.8134e+01, -1.7733e+01, -1.7435e+01,\n",
       "         -1.8683e+01, -1.8058e+01, -1.8340e+01, -1.8235e+01],\n",
       "        [-7.4385e+00, -2.9119e-04, -7.4405e+00, -5.0751e-03, -9.2383e-05,\n",
       "         -3.1828e-02, -1.2079e+00, -6.4939e-03, -7.8756e-03, -1.4482e-02,\n",
       "         -3.9132e-02, -3.5403e-02, -5.8300e-04, -3.0105e-03, -9.5793e-02,\n",
       "         -5.7226e-03, -8.0422e-04, -5.8407e-04, -2.2009e-03, -9.8943e-06,\n",
       "         -6.2972e+00, -2.0129e+01, -1.9321e+01, -1.9577e+01, -1.9169e+01,\n",
       "         -1.8605e+01, -1.8657e+01, -1.8973e+01, -2.0091e+01, -1.9903e+01,\n",
       "         -1.9210e+01, -1.8914e+01, -1.8706e+01, -1.8383e+01, -1.9240e+01,\n",
       "         -1.9971e+01, -2.0058e+01, -2.0738e+01, -2.0450e+01, -2.0753e+01,\n",
       "         -2.1843e+01, -2.2053e+01, -2.0462e+01, -1.9146e+01, -1.8892e+01,\n",
       "         -1.8862e+01, -1.8579e+01, -1.8995e+01, -1.9475e+01, -1.9173e+01,\n",
       "         -1.9558e+01, -1.9111e+01, -1.9196e+01, -1.8379e+01, -1.9143e+01,\n",
       "         -1.8814e+01, -1.9072e+01, -1.9055e+01, -1.9377e+01, -1.8646e+01,\n",
       "         -1.9579e+01, -1.8822e+01, -1.9480e+01, -1.9212e+01],\n",
       "        [-7.5122e+00, -4.0857e-04, -4.5874e-02, -1.1753e-01, -9.2398e-03,\n",
       "         -1.1621e-02, -2.1878e-01, -6.8548e-03, -5.6991e+00, -1.3638e-01,\n",
       "         -1.3983e-03, -1.5640e-01, -6.1108e-03, -1.3362e-04, -1.4782e-05,\n",
       "         -7.2653e+00, -1.9752e+01, -2.0038e+01, -2.0115e+01, -2.0586e+01,\n",
       "         -2.0834e+01, -2.0976e+01, -1.9579e+01, -2.0611e+01, -2.0632e+01,\n",
       "         -2.0930e+01, -2.0911e+01, -2.1010e+01, -1.9987e+01, -1.9576e+01,\n",
       "         -2.0044e+01, -2.0369e+01, -2.0176e+01, -1.9834e+01, -1.9485e+01,\n",
       "         -1.9454e+01, -1.9835e+01, -1.9606e+01, -1.9077e+01, -1.8564e+01,\n",
       "         -1.8978e+01, -1.7439e+01, -1.9917e+01, -2.0272e+01, -1.9958e+01,\n",
       "         -1.9948e+01, -2.0710e+01, -2.0902e+01, -2.0862e+01, -2.0465e+01,\n",
       "         -2.0097e+01, -2.0019e+01, -2.0625e+01, -2.0425e+01, -2.0342e+01,\n",
       "         -2.0488e+01, -2.0742e+01, -2.0486e+01, -2.0414e+01, -1.9393e+01,\n",
       "         -2.1141e+01, -2.0968e+01, -2.0962e+01, -2.0703e+01],\n",
       "        [-9.0572e+00, -2.1813e-02, -2.2378e-02, -9.0553e-01, -2.2039e-02,\n",
       "         -1.8983e-03, -1.4572e+00, -3.4720e-04, -8.5576e-02, -7.1460e+00,\n",
       "         -2.8603e-03, -2.0504e-05, -9.0508e+00, -2.0793e+01, -2.0654e+01,\n",
       "         -2.1492e+01, -2.0510e+01, -2.0621e+01, -2.1574e+01, -2.1253e+01,\n",
       "         -2.1525e+01, -2.1723e+01, -2.0954e+01, -2.0371e+01, -2.0516e+01,\n",
       "         -2.1078e+01, -2.0486e+01, -2.1167e+01, -2.1376e+01, -2.0382e+01,\n",
       "         -1.9986e+01, -1.9423e+01, -1.9679e+01, -2.0847e+01, -2.0000e+01,\n",
       "         -2.0012e+01, -2.1790e+01, -1.9815e+01, -2.0924e+01, -2.1684e+01,\n",
       "         -2.1884e+01, -2.0208e+01, -2.0053e+01, -1.9636e+01, -1.9287e+01,\n",
       "         -1.9608e+01, -1.8903e+01, -1.9754e+01, -2.0500e+01, -1.9552e+01,\n",
       "         -2.0701e+01, -2.0105e+01, -2.1044e+01, -2.0644e+01, -1.9275e+01,\n",
       "         -1.9831e+01, -2.1057e+01, -2.0148e+01, -2.0576e+01, -1.9030e+01,\n",
       "         -2.1594e+01, -2.0517e+01, -2.1162e+01, -2.1364e+01],\n",
       "        [-8.6530e+00, -6.0209e-03, -4.4625e-02, -4.4099e-03, -2.5430e-02,\n",
       "         -2.6179e-03, -4.1725e-03, -5.7721e-03, -4.5597e-02, -2.3816e-02,\n",
       "         -2.6161e+00, -2.0504e-02, -8.4696e+00, -3.6111e-03, -1.0022e-01,\n",
       "         -3.7675e-04, -1.6365e-03, -4.1563e-03, -2.4670e-03, -3.1427e-03,\n",
       "         -2.8774e-03, -1.9883e-03, -1.5974e-05, -7.2207e+00, -2.1707e+01,\n",
       "         -2.1270e+01, -2.0962e+01, -2.0703e+01, -2.0609e+01, -2.0761e+01,\n",
       "         -2.0732e+01, -2.0792e+01, -2.0955e+01, -1.9081e+01, -2.1401e+01,\n",
       "         -2.1941e+01, -2.2401e+01, -2.1416e+01, -2.1495e+01, -2.1851e+01,\n",
       "         -2.1430e+01, -2.0716e+01, -2.0982e+01, -2.1753e+01, -2.1286e+01,\n",
       "         -2.1287e+01, -2.0734e+01, -2.0559e+01, -2.0276e+01, -2.0278e+01,\n",
       "         -2.0720e+01, -2.0753e+01, -2.1505e+01, -2.0634e+01, -2.0806e+01,\n",
       "         -2.0381e+01, -2.0704e+01, -2.0600e+01, -2.0689e+01, -2.0010e+01,\n",
       "         -2.1547e+01, -2.1337e+01, -2.1502e+01, -2.1222e+01],\n",
       "        [-7.7992e+00, -4.4120e-03, -1.3082e-01, -1.0324e+00, -2.4741e-02,\n",
       "         -6.3542e-04, -2.6568e-04, -1.6312e-03, -1.0644e-02, -6.1661e-02,\n",
       "         -3.5549e-02, -8.1530e-04, -2.7927e-04, -5.7901e-03, -3.2492e-03,\n",
       "         -3.5016e-02, -6.5446e-02, -2.7635e-03, -4.6173e-02, -9.8943e-06,\n",
       "         -7.1336e+00, -2.1546e+01, -2.0908e+01, -2.0680e+01, -1.8841e+01,\n",
       "         -2.0150e+01, -2.0688e+01, -2.0647e+01, -2.1241e+01, -2.0368e+01,\n",
       "         -2.0631e+01, -1.9593e+01, -1.9503e+01, -1.9339e+01, -1.8255e+01,\n",
       "         -1.9254e+01, -1.9781e+01, -1.9804e+01, -2.0204e+01, -2.1094e+01,\n",
       "         -2.1448e+01, -2.1831e+01, -2.0016e+01, -1.9575e+01, -1.9119e+01,\n",
       "         -1.8721e+01, -1.9827e+01, -1.9697e+01, -2.0327e+01, -2.1114e+01,\n",
       "         -2.0609e+01, -1.9500e+01, -2.0980e+01, -2.0753e+01, -2.0147e+01,\n",
       "         -1.9865e+01, -2.0261e+01, -2.1213e+01, -2.1310e+01, -2.1135e+01,\n",
       "         -2.0445e+01, -1.9760e+01, -2.0521e+01, -1.9113e+01],\n",
       "        [-7.1212e+00, -1.2825e+00, -6.2932e-03, -1.0073e-02, -5.4597e-02,\n",
       "         -1.8117e+00, -1.5584e+01, -2.1207e+00, -6.6711e-02, -5.2452e-06,\n",
       "         -6.6947e+00, -1.8262e+01, -1.8234e+01, -1.8005e+01, -1.8341e+01,\n",
       "         -1.8554e+01, -1.8285e+01, -1.7462e+01, -1.7698e+01, -1.7601e+01,\n",
       "         -1.8429e+01, -1.8082e+01, -1.7922e+01, -1.7975e+01, -1.8606e+01,\n",
       "         -1.8807e+01, -1.8536e+01, -1.7876e+01, -1.7667e+01, -1.7572e+01,\n",
       "         -1.8365e+01, -1.8239e+01, -1.8309e+01, -1.8594e+01, -1.8668e+01,\n",
       "         -1.8862e+01, -1.9145e+01, -1.8179e+01, -1.7436e+01, -1.7423e+01,\n",
       "         -1.7446e+01, -1.7426e+01, -1.7674e+01, -1.8560e+01, -1.8828e+01,\n",
       "         -1.8884e+01, -1.8503e+01, -1.8968e+01, -1.8833e+01, -1.7459e+01,\n",
       "         -1.8379e+01, -1.8536e+01, -1.8463e+01, -1.8069e+01, -1.8090e+01,\n",
       "         -1.8248e+01, -1.7955e+01, -1.8487e+01, -1.8065e+01, -1.7578e+01,\n",
       "         -1.8402e+01, -1.8627e+01, -1.7892e+01, -1.8237e+01],\n",
       "        [-9.5946e+00, -8.3259e-03, -9.4965e-03, -1.0859e-02, -1.9817e-03,\n",
       "         -7.8008e-03, -4.2506e+00, -1.1485e-01, -1.1864e-03, -5.8182e-01,\n",
       "         -5.3644e-06, -1.0055e-01, -2.2313e-02, -7.5562e-04, -1.0559e-02,\n",
       "         -2.6208e-03, -4.4363e-03, -2.0099e+00, -9.5053e+00, -1.1243e-01,\n",
       "         -6.2291e-04, -6.4373e-06, -8.3617e+00, -1.9541e+01, -1.9356e+01,\n",
       "         -1.9107e+01, -1.9257e+01, -1.9284e+01, -1.9441e+01, -1.9081e+01,\n",
       "         -1.9627e+01, -1.9430e+01, -1.9018e+01, -1.8933e+01, -1.9092e+01,\n",
       "         -1.9317e+01, -1.8918e+01, -1.8904e+01, -1.9395e+01, -1.8947e+01,\n",
       "         -1.9014e+01, -1.9730e+01, -1.9732e+01, -1.8898e+01, -1.9225e+01,\n",
       "         -1.9443e+01, -1.8887e+01, -1.8636e+01, -1.8779e+01, -1.8876e+01,\n",
       "         -1.9647e+01, -1.8883e+01, -1.9017e+01, -1.9362e+01, -1.9279e+01,\n",
       "         -1.9407e+01, -1.9470e+01, -1.9328e+01, -1.9452e+01, -1.8816e+01,\n",
       "         -1.9840e+01, -1.8867e+01, -1.9041e+01, -1.9015e+01],\n",
       "        [-8.8160e+00, -2.2354e+01, -6.4917e+00, -1.8482e+01, -1.8206e+01,\n",
       "         -1.8720e+01, -1.8637e+01, -1.8661e+01, -1.8473e+01, -1.8693e+01,\n",
       "         -1.8891e+01, -1.8318e+01, -1.8315e+01, -1.8386e+01, -1.8464e+01,\n",
       "         -1.8576e+01, -1.8431e+01, -2.9258e+01, -1.8222e+01, -1.8632e+01,\n",
       "         -2.7657e+01, -1.8819e+01, -1.8955e+01, -1.8412e+01, -1.8880e+01,\n",
       "         -1.8474e+01, -1.8533e+01, -1.8335e+01, -1.8566e+01, -1.8742e+01,\n",
       "         -1.8403e+01, -1.8570e+01, -1.8603e+01, -1.8440e+01, -1.8699e+01,\n",
       "         -1.8811e+01, -1.8834e+01, -2.7473e+01, -1.8453e+01, -1.8779e+01,\n",
       "         -1.8502e+01, -2.3371e+01, -1.8664e+01, -1.8785e+01, -1.8623e+01,\n",
       "         -1.8986e+01, -1.8378e+01, -1.8752e+01, -1.8591e+01, -1.8226e+01,\n",
       "         -1.8429e+01, -1.8287e+01, -1.8961e+01, -1.8087e+01, -1.8349e+01,\n",
       "         -1.8151e+01, -1.8823e+01, -1.8623e+01, -2.7850e+01, -1.8618e+01,\n",
       "         -1.8722e+01, -1.8497e+01, -1.8799e+01, -1.8559e+01],\n",
       "        [-8.9455e+00, -2.2020e-03, -5.9587e-01, -8.8932e-01, -5.5686e-02,\n",
       "         -1.6661e+01, -8.6193e+00, -1.8765e+01, -1.8708e+01, -1.8558e+01,\n",
       "         -1.8371e+01, -1.8209e+01, -1.8107e+01, -1.7788e+01, -1.8574e+01,\n",
       "         -1.8370e+01, -1.7887e+01, -1.8340e+01, -1.8380e+01, -1.9092e+01,\n",
       "         -1.8379e+01, -1.8268e+01, -1.8522e+01, -1.8316e+01, -2.6778e+01,\n",
       "         -1.8647e+01, -1.8532e+01, -1.8089e+01, -1.8052e+01, -1.8367e+01,\n",
       "         -1.8342e+01, -1.7921e+01, -1.8426e+01, -1.8432e+01, -1.7840e+01,\n",
       "         -1.8428e+01, -1.8162e+01, -1.7822e+01, -1.8201e+01, -1.8030e+01,\n",
       "         -1.7689e+01, -1.7274e+01, -2.8006e+01, -2.8357e+01, -2.2596e+01,\n",
       "         -1.9128e+01, -1.8241e+01, -1.8474e+01, -1.8759e+01, -1.8079e+01,\n",
       "         -1.7898e+01, -1.7854e+01, -1.8626e+01, -1.7937e+01, -1.7783e+01,\n",
       "         -1.7922e+01, -1.8144e+01, -1.8214e+01, -1.8192e+01, -1.7480e+01,\n",
       "         -1.8345e+01, -1.8208e+01, -1.8118e+01, -1.8043e+01],\n",
       "        [-8.8334e+00, -3.1082e-03, -2.4370e-02, -8.4591e-04, -4.5165e-03,\n",
       "         -2.5948e-04, -2.7577e+01, -8.0598e+00, -2.6333e+01, -2.3541e+01,\n",
       "         -2.5298e+01, -1.9281e+01, -2.3504e+01, -1.9625e+01, -1.8931e+01,\n",
       "         -2.0383e+01, -1.9986e+01, -1.9399e+01, -2.5851e+01, -2.0356e+01,\n",
       "         -2.5355e+01, -1.9923e+01, -2.0178e+01, -2.2339e+01, -2.8468e+01,\n",
       "         -2.8650e+01, -2.3151e+01, -2.0458e+01, -2.0796e+01, -2.4794e+01,\n",
       "         -2.9090e+01, -2.8533e+01, -2.8608e+01, -2.7870e+01, -2.5586e+01,\n",
       "         -2.0855e+01, -2.0357e+01, -2.0532e+01, -2.0607e+01, -2.0193e+01,\n",
       "         -2.0278e+01, -2.0685e+01, -2.8509e+01, -2.9220e+01, -2.9310e+01,\n",
       "         -2.9133e+01, -2.8551e+01, -2.8795e+01, -2.6573e+01, -2.0240e+01,\n",
       "         -2.0128e+01, -2.7622e+01, -2.7099e+01, -2.6859e+01, -2.0069e+01,\n",
       "         -2.7731e+01, -2.4372e+01, -2.6695e+01, -1.9634e+01, -2.0016e+01,\n",
       "         -1.9557e+01, -2.0483e+01, -2.0913e+01, -2.7647e+01],\n",
       "        [-9.4318e+00, -2.7238e-02, -4.6606e-03, -1.3805e-01, -2.5097e+01,\n",
       "         -9.1529e+00, -2.2190e+01, -2.1661e+01, -2.1899e+01, -2.1798e+01,\n",
       "         -2.1952e+01, -2.1949e+01, -2.2241e+01, -2.1762e+01, -2.2026e+01,\n",
       "         -2.1210e+01, -2.2072e+01, -2.1756e+01, -2.1265e+01, -2.1297e+01,\n",
       "         -2.2411e+01, -2.1388e+01, -2.2278e+01, -2.4551e+01, -2.2252e+01,\n",
       "         -2.1373e+01, -2.1692e+01, -2.1230e+01, -2.2249e+01, -2.2131e+01,\n",
       "         -2.1719e+01, -2.8416e+01, -2.2662e+01, -2.1115e+01, -2.5482e+01,\n",
       "         -2.2396e+01, -2.0472e+01, -2.1889e+01, -2.1175e+01, -1.9116e+01,\n",
       "         -2.0981e+01, -2.8657e+01, -2.8724e+01, -2.2390e+01, -2.6068e+01,\n",
       "         -2.1902e+01, -2.0157e+01, -2.7385e+01, -2.1095e+01, -2.0688e+01,\n",
       "         -2.1670e+01, -2.6603e+01, -2.1634e+01, -2.1837e+01, -2.1351e+01,\n",
       "         -2.1250e+01, -2.6620e+01, -2.2251e+01, -2.0959e+01, -2.0569e+01,\n",
       "         -2.2091e+01, -2.2252e+01, -2.2014e+01, -2.1769e+01],\n",
       "        [-9.0732e+00, -8.7394e-03, -5.5703e-04, -4.3968e-01, -2.8028e-01,\n",
       "         -3.5060e-03, -1.5308e-02, -1.2027e-03, -1.4755e-01, -2.5308e-03,\n",
       "         -9.3109e-03, -7.4148e-03, -9.8754e-03, -5.2452e-06, -7.4072e+00,\n",
       "         -1.8722e+01, -1.9121e+01, -1.8967e+01, -1.8118e+01, -1.9040e+01,\n",
       "         -1.9155e+01, -1.8867e+01, -1.9211e+01, -1.9320e+01, -1.9141e+01,\n",
       "         -1.8937e+01, -1.9236e+01, -1.9244e+01, -1.9246e+01, -1.9269e+01,\n",
       "         -1.9572e+01, -1.9358e+01, -1.9010e+01, -1.8889e+01, -1.8491e+01,\n",
       "         -1.9041e+01, -1.8749e+01, -1.8591e+01, -1.8513e+01, -1.8916e+01,\n",
       "         -1.9263e+01, -1.8770e+01, -1.9695e+01, -1.8777e+01, -1.8389e+01,\n",
       "         -1.8762e+01, -1.8422e+01, -1.8451e+01, -1.8547e+01, -1.7701e+01,\n",
       "         -1.8878e+01, -1.8616e+01, -1.8794e+01, -1.8580e+01, -1.9074e+01,\n",
       "         -1.9084e+01, -1.9149e+01, -1.8946e+01, -1.9829e+01, -1.8561e+01,\n",
       "         -1.9144e+01, -1.9263e+01, -1.9638e+01, -1.8686e+01]], device='cuda:0',\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f.reshape(14*64,-1)[torch.arange(14*64),input_ids.reshape(14*64)].reshape(14,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "efcd6fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-7.4231e+00],\n",
       "         [-2.5424e-03],\n",
       "         [-1.3525e+01],\n",
       "         [-1.7025e-01],\n",
       "         [-2.7737e-03],\n",
       "         [-8.5081e-02],\n",
       "         [-2.8930e+00],\n",
       "         [-1.9277e-03],\n",
       "         [-1.7764e-03],\n",
       "         [-7.5102e-06],\n",
       "         [-6.4597e+00],\n",
       "         [-1.9890e+01],\n",
       "         [-1.9577e+01],\n",
       "         [-1.9099e+01],\n",
       "         [-1.9004e+01],\n",
       "         [-1.9502e+01],\n",
       "         [-1.9159e+01],\n",
       "         [-1.9449e+01],\n",
       "         [-1.9208e+01],\n",
       "         [-1.9487e+01],\n",
       "         [-1.9848e+01],\n",
       "         [-1.9766e+01],\n",
       "         [-1.9482e+01],\n",
       "         [-1.9291e+01],\n",
       "         [-1.9714e+01],\n",
       "         [-1.9686e+01],\n",
       "         [-1.9809e+01],\n",
       "         [-2.0063e+01],\n",
       "         [-1.9529e+01],\n",
       "         [-1.9244e+01],\n",
       "         [-1.9632e+01],\n",
       "         [-1.9619e+01],\n",
       "         [-1.9810e+01],\n",
       "         [-2.0467e+01],\n",
       "         [-2.0178e+01],\n",
       "         [-1.9932e+01],\n",
       "         [-2.1677e+01],\n",
       "         [-1.9791e+01],\n",
       "         [-1.9139e+01],\n",
       "         [-1.9575e+01],\n",
       "         [-1.9524e+01],\n",
       "         [-1.9283e+01],\n",
       "         [-1.9593e+01],\n",
       "         [-1.9684e+01],\n",
       "         [-1.9980e+01],\n",
       "         [-2.0379e+01],\n",
       "         [-1.9975e+01],\n",
       "         [-2.6268e+01],\n",
       "         [-2.0648e+01],\n",
       "         [-1.9679e+01],\n",
       "         [-1.9538e+01],\n",
       "         [-1.9053e+01],\n",
       "         [-1.9899e+01],\n",
       "         [-1.8803e+01],\n",
       "         [-1.8870e+01],\n",
       "         [-1.8950e+01],\n",
       "         [-1.9200e+01],\n",
       "         [-1.9063e+01],\n",
       "         [-1.9097e+01],\n",
       "         [-1.8958e+01],\n",
       "         [-1.9803e+01],\n",
       "         [-1.9147e+01],\n",
       "         [-1.9711e+01],\n",
       "         [-1.9533e+01]],\n",
       "\n",
       "        [[-8.9505e+00],\n",
       "         [-7.1464e-04],\n",
       "         [-2.3362e-02],\n",
       "         [-5.3881e-05],\n",
       "         [-9.4423e-03],\n",
       "         [-4.0220e-03],\n",
       "         [-6.0479e-03],\n",
       "         [-1.2984e-03],\n",
       "         [-3.8084e-03],\n",
       "         [-1.2040e-05],\n",
       "         [-9.6045e+00],\n",
       "         [-1.8703e+01],\n",
       "         [-1.8399e+01],\n",
       "         [-1.8059e+01],\n",
       "         [-1.8071e+01],\n",
       "         [-1.7826e+01],\n",
       "         [-1.7909e+01],\n",
       "         [-1.7572e+01],\n",
       "         [-1.8625e+01],\n",
       "         [-1.8307e+01],\n",
       "         [-1.8297e+01],\n",
       "         [-1.8414e+01],\n",
       "         [-1.8143e+01],\n",
       "         [-1.8289e+01],\n",
       "         [-1.7841e+01],\n",
       "         [-1.9010e+01],\n",
       "         [-1.9772e+01],\n",
       "         [-1.8900e+01],\n",
       "         [-1.7972e+01],\n",
       "         [-1.8717e+01],\n",
       "         [-1.9376e+01],\n",
       "         [-1.8186e+01],\n",
       "         [-1.7669e+01],\n",
       "         [-2.0915e+01],\n",
       "         [-2.3747e+01],\n",
       "         [-1.9806e+01],\n",
       "         [-2.0814e+01],\n",
       "         [-1.8911e+01],\n",
       "         [-1.8089e+01],\n",
       "         [-1.7328e+01],\n",
       "         [-1.8057e+01],\n",
       "         [-1.7527e+01],\n",
       "         [-1.7983e+01],\n",
       "         [-1.7560e+01],\n",
       "         [-1.9104e+01],\n",
       "         [-1.8124e+01],\n",
       "         [-1.7537e+01],\n",
       "         [-2.0731e+01],\n",
       "         [-1.9943e+01],\n",
       "         [-1.8972e+01],\n",
       "         [-1.8953e+01],\n",
       "         [-1.9290e+01],\n",
       "         [-1.9179e+01],\n",
       "         [-1.7492e+01],\n",
       "         [-1.7929e+01],\n",
       "         [-1.7399e+01],\n",
       "         [-1.8292e+01],\n",
       "         [-1.8134e+01],\n",
       "         [-1.7733e+01],\n",
       "         [-1.7435e+01],\n",
       "         [-1.8683e+01],\n",
       "         [-1.8058e+01],\n",
       "         [-1.8340e+01],\n",
       "         [-1.8235e+01]],\n",
       "\n",
       "        [[-7.4385e+00],\n",
       "         [-2.9119e-04],\n",
       "         [-7.4405e+00],\n",
       "         [-5.0751e-03],\n",
       "         [-9.2383e-05],\n",
       "         [-3.1828e-02],\n",
       "         [-1.2079e+00],\n",
       "         [-6.4939e-03],\n",
       "         [-7.8756e-03],\n",
       "         [-1.4482e-02],\n",
       "         [-3.9132e-02],\n",
       "         [-3.5403e-02],\n",
       "         [-5.8300e-04],\n",
       "         [-3.0105e-03],\n",
       "         [-9.5793e-02],\n",
       "         [-5.7226e-03],\n",
       "         [-8.0422e-04],\n",
       "         [-5.8407e-04],\n",
       "         [-2.2009e-03],\n",
       "         [-9.8943e-06],\n",
       "         [-6.2972e+00],\n",
       "         [-2.0129e+01],\n",
       "         [-1.9321e+01],\n",
       "         [-1.9577e+01],\n",
       "         [-1.9169e+01],\n",
       "         [-1.8605e+01],\n",
       "         [-1.8657e+01],\n",
       "         [-1.8973e+01],\n",
       "         [-2.0091e+01],\n",
       "         [-1.9903e+01],\n",
       "         [-1.9210e+01],\n",
       "         [-1.8914e+01],\n",
       "         [-1.8706e+01],\n",
       "         [-1.8383e+01],\n",
       "         [-1.9240e+01],\n",
       "         [-1.9971e+01],\n",
       "         [-2.0058e+01],\n",
       "         [-2.0738e+01],\n",
       "         [-2.0450e+01],\n",
       "         [-2.0753e+01],\n",
       "         [-2.1843e+01],\n",
       "         [-2.2053e+01],\n",
       "         [-2.0462e+01],\n",
       "         [-1.9146e+01],\n",
       "         [-1.8892e+01],\n",
       "         [-1.8862e+01],\n",
       "         [-1.8579e+01],\n",
       "         [-1.8995e+01],\n",
       "         [-1.9475e+01],\n",
       "         [-1.9173e+01],\n",
       "         [-1.9558e+01],\n",
       "         [-1.9111e+01],\n",
       "         [-1.9196e+01],\n",
       "         [-1.8379e+01],\n",
       "         [-1.9143e+01],\n",
       "         [-1.8814e+01],\n",
       "         [-1.9072e+01],\n",
       "         [-1.9055e+01],\n",
       "         [-1.9377e+01],\n",
       "         [-1.8646e+01],\n",
       "         [-1.9579e+01],\n",
       "         [-1.8822e+01],\n",
       "         [-1.9480e+01],\n",
       "         [-1.9212e+01]],\n",
       "\n",
       "        [[-7.5122e+00],\n",
       "         [-4.0857e-04],\n",
       "         [-4.5874e-02],\n",
       "         [-1.1753e-01],\n",
       "         [-9.2398e-03],\n",
       "         [-1.1621e-02],\n",
       "         [-2.1878e-01],\n",
       "         [-6.8548e-03],\n",
       "         [-5.6991e+00],\n",
       "         [-1.3638e-01],\n",
       "         [-1.3983e-03],\n",
       "         [-1.5640e-01],\n",
       "         [-6.1108e-03],\n",
       "         [-1.3362e-04],\n",
       "         [-1.4782e-05],\n",
       "         [-7.2653e+00],\n",
       "         [-1.9752e+01],\n",
       "         [-2.0038e+01],\n",
       "         [-2.0115e+01],\n",
       "         [-2.0586e+01],\n",
       "         [-2.0834e+01],\n",
       "         [-2.0976e+01],\n",
       "         [-1.9579e+01],\n",
       "         [-2.0611e+01],\n",
       "         [-2.0632e+01],\n",
       "         [-2.0930e+01],\n",
       "         [-2.0911e+01],\n",
       "         [-2.1010e+01],\n",
       "         [-1.9987e+01],\n",
       "         [-1.9576e+01],\n",
       "         [-2.0044e+01],\n",
       "         [-2.0369e+01],\n",
       "         [-2.0176e+01],\n",
       "         [-1.9834e+01],\n",
       "         [-1.9485e+01],\n",
       "         [-1.9454e+01],\n",
       "         [-1.9835e+01],\n",
       "         [-1.9606e+01],\n",
       "         [-1.9077e+01],\n",
       "         [-1.8564e+01],\n",
       "         [-1.8978e+01],\n",
       "         [-1.7439e+01],\n",
       "         [-1.9917e+01],\n",
       "         [-2.0272e+01],\n",
       "         [-1.9958e+01],\n",
       "         [-1.9948e+01],\n",
       "         [-2.0710e+01],\n",
       "         [-2.0902e+01],\n",
       "         [-2.0862e+01],\n",
       "         [-2.0465e+01],\n",
       "         [-2.0097e+01],\n",
       "         [-2.0019e+01],\n",
       "         [-2.0625e+01],\n",
       "         [-2.0425e+01],\n",
       "         [-2.0342e+01],\n",
       "         [-2.0488e+01],\n",
       "         [-2.0742e+01],\n",
       "         [-2.0486e+01],\n",
       "         [-2.0414e+01],\n",
       "         [-1.9393e+01],\n",
       "         [-2.1141e+01],\n",
       "         [-2.0968e+01],\n",
       "         [-2.0962e+01],\n",
       "         [-2.0703e+01]],\n",
       "\n",
       "        [[-9.0572e+00],\n",
       "         [-2.1813e-02],\n",
       "         [-2.2378e-02],\n",
       "         [-9.0553e-01],\n",
       "         [-2.2039e-02],\n",
       "         [-1.8983e-03],\n",
       "         [-1.4572e+00],\n",
       "         [-3.4720e-04],\n",
       "         [-8.5576e-02],\n",
       "         [-7.1460e+00],\n",
       "         [-2.8603e-03],\n",
       "         [-2.0504e-05],\n",
       "         [-9.0508e+00],\n",
       "         [-2.0793e+01],\n",
       "         [-2.0654e+01],\n",
       "         [-2.1492e+01],\n",
       "         [-2.0510e+01],\n",
       "         [-2.0621e+01],\n",
       "         [-2.1574e+01],\n",
       "         [-2.1253e+01],\n",
       "         [-2.1525e+01],\n",
       "         [-2.1723e+01],\n",
       "         [-2.0954e+01],\n",
       "         [-2.0371e+01],\n",
       "         [-2.0516e+01],\n",
       "         [-2.1078e+01],\n",
       "         [-2.0486e+01],\n",
       "         [-2.1167e+01],\n",
       "         [-2.1376e+01],\n",
       "         [-2.0382e+01],\n",
       "         [-1.9986e+01],\n",
       "         [-1.9423e+01],\n",
       "         [-1.9679e+01],\n",
       "         [-2.0847e+01],\n",
       "         [-2.0000e+01],\n",
       "         [-2.0012e+01],\n",
       "         [-2.1790e+01],\n",
       "         [-1.9815e+01],\n",
       "         [-2.0924e+01],\n",
       "         [-2.1684e+01],\n",
       "         [-2.1884e+01],\n",
       "         [-2.0208e+01],\n",
       "         [-2.0053e+01],\n",
       "         [-1.9636e+01],\n",
       "         [-1.9287e+01],\n",
       "         [-1.9608e+01],\n",
       "         [-1.8903e+01],\n",
       "         [-1.9754e+01],\n",
       "         [-2.0500e+01],\n",
       "         [-1.9552e+01],\n",
       "         [-2.0701e+01],\n",
       "         [-2.0105e+01],\n",
       "         [-2.1044e+01],\n",
       "         [-2.0644e+01],\n",
       "         [-1.9275e+01],\n",
       "         [-1.9831e+01],\n",
       "         [-2.1057e+01],\n",
       "         [-2.0148e+01],\n",
       "         [-2.0576e+01],\n",
       "         [-1.9030e+01],\n",
       "         [-2.1594e+01],\n",
       "         [-2.0517e+01],\n",
       "         [-2.1162e+01],\n",
       "         [-2.1364e+01]],\n",
       "\n",
       "        [[-8.6530e+00],\n",
       "         [-6.0209e-03],\n",
       "         [-4.4625e-02],\n",
       "         [-4.4099e-03],\n",
       "         [-2.5430e-02],\n",
       "         [-2.6179e-03],\n",
       "         [-4.1725e-03],\n",
       "         [-5.7721e-03],\n",
       "         [-4.5597e-02],\n",
       "         [-2.3816e-02],\n",
       "         [-2.6161e+00],\n",
       "         [-2.0504e-02],\n",
       "         [-8.4696e+00],\n",
       "         [-3.6111e-03],\n",
       "         [-1.0022e-01],\n",
       "         [-3.7675e-04],\n",
       "         [-1.6365e-03],\n",
       "         [-4.1563e-03],\n",
       "         [-2.4670e-03],\n",
       "         [-3.1427e-03],\n",
       "         [-2.8774e-03],\n",
       "         [-1.9883e-03],\n",
       "         [-1.5974e-05],\n",
       "         [-7.2207e+00],\n",
       "         [-2.1707e+01],\n",
       "         [-2.1270e+01],\n",
       "         [-2.0962e+01],\n",
       "         [-2.0703e+01],\n",
       "         [-2.0609e+01],\n",
       "         [-2.0761e+01],\n",
       "         [-2.0732e+01],\n",
       "         [-2.0792e+01],\n",
       "         [-2.0955e+01],\n",
       "         [-1.9081e+01],\n",
       "         [-2.1401e+01],\n",
       "         [-2.1941e+01],\n",
       "         [-2.2401e+01],\n",
       "         [-2.1416e+01],\n",
       "         [-2.1495e+01],\n",
       "         [-2.1851e+01],\n",
       "         [-2.1430e+01],\n",
       "         [-2.0716e+01],\n",
       "         [-2.0982e+01],\n",
       "         [-2.1753e+01],\n",
       "         [-2.1286e+01],\n",
       "         [-2.1287e+01],\n",
       "         [-2.0734e+01],\n",
       "         [-2.0559e+01],\n",
       "         [-2.0276e+01],\n",
       "         [-2.0278e+01],\n",
       "         [-2.0720e+01],\n",
       "         [-2.0753e+01],\n",
       "         [-2.1505e+01],\n",
       "         [-2.0634e+01],\n",
       "         [-2.0806e+01],\n",
       "         [-2.0381e+01],\n",
       "         [-2.0704e+01],\n",
       "         [-2.0600e+01],\n",
       "         [-2.0689e+01],\n",
       "         [-2.0010e+01],\n",
       "         [-2.1547e+01],\n",
       "         [-2.1337e+01],\n",
       "         [-2.1502e+01],\n",
       "         [-2.1222e+01]],\n",
       "\n",
       "        [[-7.7992e+00],\n",
       "         [-4.4120e-03],\n",
       "         [-1.3082e-01],\n",
       "         [-1.0324e+00],\n",
       "         [-2.4741e-02],\n",
       "         [-6.3542e-04],\n",
       "         [-2.6568e-04],\n",
       "         [-1.6312e-03],\n",
       "         [-1.0644e-02],\n",
       "         [-6.1661e-02],\n",
       "         [-3.5549e-02],\n",
       "         [-8.1530e-04],\n",
       "         [-2.7927e-04],\n",
       "         [-5.7901e-03],\n",
       "         [-3.2492e-03],\n",
       "         [-3.5016e-02],\n",
       "         [-6.5446e-02],\n",
       "         [-2.7635e-03],\n",
       "         [-4.6173e-02],\n",
       "         [-9.8943e-06],\n",
       "         [-7.1336e+00],\n",
       "         [-2.1546e+01],\n",
       "         [-2.0908e+01],\n",
       "         [-2.0680e+01],\n",
       "         [-1.8841e+01],\n",
       "         [-2.0150e+01],\n",
       "         [-2.0688e+01],\n",
       "         [-2.0647e+01],\n",
       "         [-2.1241e+01],\n",
       "         [-2.0368e+01],\n",
       "         [-2.0631e+01],\n",
       "         [-1.9593e+01],\n",
       "         [-1.9503e+01],\n",
       "         [-1.9339e+01],\n",
       "         [-1.8255e+01],\n",
       "         [-1.9254e+01],\n",
       "         [-1.9781e+01],\n",
       "         [-1.9804e+01],\n",
       "         [-2.0204e+01],\n",
       "         [-2.1094e+01],\n",
       "         [-2.1448e+01],\n",
       "         [-2.1831e+01],\n",
       "         [-2.0016e+01],\n",
       "         [-1.9575e+01],\n",
       "         [-1.9119e+01],\n",
       "         [-1.8721e+01],\n",
       "         [-1.9827e+01],\n",
       "         [-1.9697e+01],\n",
       "         [-2.0327e+01],\n",
       "         [-2.1114e+01],\n",
       "         [-2.0609e+01],\n",
       "         [-1.9500e+01],\n",
       "         [-2.0980e+01],\n",
       "         [-2.0753e+01],\n",
       "         [-2.0147e+01],\n",
       "         [-1.9865e+01],\n",
       "         [-2.0261e+01],\n",
       "         [-2.1213e+01],\n",
       "         [-2.1310e+01],\n",
       "         [-2.1135e+01],\n",
       "         [-2.0445e+01],\n",
       "         [-1.9760e+01],\n",
       "         [-2.0521e+01],\n",
       "         [-1.9113e+01]],\n",
       "\n",
       "        [[-7.1212e+00],\n",
       "         [-1.2825e+00],\n",
       "         [-6.2932e-03],\n",
       "         [-1.0073e-02],\n",
       "         [-5.4597e-02],\n",
       "         [-1.8117e+00],\n",
       "         [-1.5584e+01],\n",
       "         [-2.1207e+00],\n",
       "         [-6.6711e-02],\n",
       "         [-5.2452e-06],\n",
       "         [-6.6947e+00],\n",
       "         [-1.8262e+01],\n",
       "         [-1.8234e+01],\n",
       "         [-1.8005e+01],\n",
       "         [-1.8341e+01],\n",
       "         [-1.8554e+01],\n",
       "         [-1.8285e+01],\n",
       "         [-1.7462e+01],\n",
       "         [-1.7698e+01],\n",
       "         [-1.7601e+01],\n",
       "         [-1.8429e+01],\n",
       "         [-1.8082e+01],\n",
       "         [-1.7922e+01],\n",
       "         [-1.7975e+01],\n",
       "         [-1.8606e+01],\n",
       "         [-1.8807e+01],\n",
       "         [-1.8536e+01],\n",
       "         [-1.7876e+01],\n",
       "         [-1.7667e+01],\n",
       "         [-1.7572e+01],\n",
       "         [-1.8365e+01],\n",
       "         [-1.8239e+01],\n",
       "         [-1.8309e+01],\n",
       "         [-1.8594e+01],\n",
       "         [-1.8668e+01],\n",
       "         [-1.8862e+01],\n",
       "         [-1.9145e+01],\n",
       "         [-1.8179e+01],\n",
       "         [-1.7436e+01],\n",
       "         [-1.7423e+01],\n",
       "         [-1.7446e+01],\n",
       "         [-1.7426e+01],\n",
       "         [-1.7674e+01],\n",
       "         [-1.8560e+01],\n",
       "         [-1.8828e+01],\n",
       "         [-1.8884e+01],\n",
       "         [-1.8503e+01],\n",
       "         [-1.8968e+01],\n",
       "         [-1.8833e+01],\n",
       "         [-1.7459e+01],\n",
       "         [-1.8379e+01],\n",
       "         [-1.8536e+01],\n",
       "         [-1.8463e+01],\n",
       "         [-1.8069e+01],\n",
       "         [-1.8090e+01],\n",
       "         [-1.8248e+01],\n",
       "         [-1.7955e+01],\n",
       "         [-1.8487e+01],\n",
       "         [-1.8065e+01],\n",
       "         [-1.7578e+01],\n",
       "         [-1.8402e+01],\n",
       "         [-1.8627e+01],\n",
       "         [-1.7892e+01],\n",
       "         [-1.8237e+01]],\n",
       "\n",
       "        [[-9.5946e+00],\n",
       "         [-8.3259e-03],\n",
       "         [-9.4965e-03],\n",
       "         [-1.0859e-02],\n",
       "         [-1.9817e-03],\n",
       "         [-7.8008e-03],\n",
       "         [-4.2506e+00],\n",
       "         [-1.1485e-01],\n",
       "         [-1.1864e-03],\n",
       "         [-5.8182e-01],\n",
       "         [-5.3644e-06],\n",
       "         [-1.0055e-01],\n",
       "         [-2.2313e-02],\n",
       "         [-7.5562e-04],\n",
       "         [-1.0559e-02],\n",
       "         [-2.6208e-03],\n",
       "         [-4.4363e-03],\n",
       "         [-2.0099e+00],\n",
       "         [-9.5053e+00],\n",
       "         [-1.1243e-01],\n",
       "         [-6.2291e-04],\n",
       "         [-6.4373e-06],\n",
       "         [-8.3617e+00],\n",
       "         [-1.9541e+01],\n",
       "         [-1.9356e+01],\n",
       "         [-1.9107e+01],\n",
       "         [-1.9257e+01],\n",
       "         [-1.9284e+01],\n",
       "         [-1.9441e+01],\n",
       "         [-1.9081e+01],\n",
       "         [-1.9627e+01],\n",
       "         [-1.9430e+01],\n",
       "         [-1.9018e+01],\n",
       "         [-1.8933e+01],\n",
       "         [-1.9092e+01],\n",
       "         [-1.9317e+01],\n",
       "         [-1.8918e+01],\n",
       "         [-1.8904e+01],\n",
       "         [-1.9395e+01],\n",
       "         [-1.8947e+01],\n",
       "         [-1.9014e+01],\n",
       "         [-1.9730e+01],\n",
       "         [-1.9732e+01],\n",
       "         [-1.8898e+01],\n",
       "         [-1.9225e+01],\n",
       "         [-1.9443e+01],\n",
       "         [-1.8887e+01],\n",
       "         [-1.8636e+01],\n",
       "         [-1.8779e+01],\n",
       "         [-1.8876e+01],\n",
       "         [-1.9647e+01],\n",
       "         [-1.8883e+01],\n",
       "         [-1.9017e+01],\n",
       "         [-1.9362e+01],\n",
       "         [-1.9279e+01],\n",
       "         [-1.9407e+01],\n",
       "         [-1.9470e+01],\n",
       "         [-1.9328e+01],\n",
       "         [-1.9452e+01],\n",
       "         [-1.8816e+01],\n",
       "         [-1.9840e+01],\n",
       "         [-1.8867e+01],\n",
       "         [-1.9041e+01],\n",
       "         [-1.9015e+01]],\n",
       "\n",
       "        [[-8.8160e+00],\n",
       "         [-2.2354e+01],\n",
       "         [-6.4917e+00],\n",
       "         [-1.8482e+01],\n",
       "         [-1.8206e+01],\n",
       "         [-1.8720e+01],\n",
       "         [-1.8637e+01],\n",
       "         [-1.8661e+01],\n",
       "         [-1.8473e+01],\n",
       "         [-1.8693e+01],\n",
       "         [-1.8891e+01],\n",
       "         [-1.8318e+01],\n",
       "         [-1.8315e+01],\n",
       "         [-1.8386e+01],\n",
       "         [-1.8464e+01],\n",
       "         [-1.8576e+01],\n",
       "         [-1.8431e+01],\n",
       "         [-2.9258e+01],\n",
       "         [-1.8222e+01],\n",
       "         [-1.8632e+01],\n",
       "         [-2.7657e+01],\n",
       "         [-1.8819e+01],\n",
       "         [-1.8955e+01],\n",
       "         [-1.8412e+01],\n",
       "         [-1.8880e+01],\n",
       "         [-1.8474e+01],\n",
       "         [-1.8533e+01],\n",
       "         [-1.8335e+01],\n",
       "         [-1.8566e+01],\n",
       "         [-1.8742e+01],\n",
       "         [-1.8403e+01],\n",
       "         [-1.8570e+01],\n",
       "         [-1.8603e+01],\n",
       "         [-1.8440e+01],\n",
       "         [-1.8699e+01],\n",
       "         [-1.8811e+01],\n",
       "         [-1.8834e+01],\n",
       "         [-2.7473e+01],\n",
       "         [-1.8453e+01],\n",
       "         [-1.8779e+01],\n",
       "         [-1.8502e+01],\n",
       "         [-2.3371e+01],\n",
       "         [-1.8664e+01],\n",
       "         [-1.8785e+01],\n",
       "         [-1.8623e+01],\n",
       "         [-1.8986e+01],\n",
       "         [-1.8378e+01],\n",
       "         [-1.8752e+01],\n",
       "         [-1.8591e+01],\n",
       "         [-1.8226e+01],\n",
       "         [-1.8429e+01],\n",
       "         [-1.8287e+01],\n",
       "         [-1.8961e+01],\n",
       "         [-1.8087e+01],\n",
       "         [-1.8349e+01],\n",
       "         [-1.8151e+01],\n",
       "         [-1.8823e+01],\n",
       "         [-1.8623e+01],\n",
       "         [-2.7850e+01],\n",
       "         [-1.8618e+01],\n",
       "         [-1.8722e+01],\n",
       "         [-1.8497e+01],\n",
       "         [-1.8799e+01],\n",
       "         [-1.8559e+01]],\n",
       "\n",
       "        [[-8.9455e+00],\n",
       "         [-2.2020e-03],\n",
       "         [-5.9587e-01],\n",
       "         [-8.8932e-01],\n",
       "         [-5.5686e-02],\n",
       "         [-1.6661e+01],\n",
       "         [-8.6193e+00],\n",
       "         [-1.8765e+01],\n",
       "         [-1.8708e+01],\n",
       "         [-1.8558e+01],\n",
       "         [-1.8371e+01],\n",
       "         [-1.8209e+01],\n",
       "         [-1.8107e+01],\n",
       "         [-1.7788e+01],\n",
       "         [-1.8574e+01],\n",
       "         [-1.8370e+01],\n",
       "         [-1.7887e+01],\n",
       "         [-1.8340e+01],\n",
       "         [-1.8380e+01],\n",
       "         [-1.9092e+01],\n",
       "         [-1.8379e+01],\n",
       "         [-1.8268e+01],\n",
       "         [-1.8522e+01],\n",
       "         [-1.8316e+01],\n",
       "         [-2.6778e+01],\n",
       "         [-1.8647e+01],\n",
       "         [-1.8532e+01],\n",
       "         [-1.8089e+01],\n",
       "         [-1.8052e+01],\n",
       "         [-1.8367e+01],\n",
       "         [-1.8342e+01],\n",
       "         [-1.7921e+01],\n",
       "         [-1.8426e+01],\n",
       "         [-1.8432e+01],\n",
       "         [-1.7840e+01],\n",
       "         [-1.8428e+01],\n",
       "         [-1.8162e+01],\n",
       "         [-1.7822e+01],\n",
       "         [-1.8201e+01],\n",
       "         [-1.8030e+01],\n",
       "         [-1.7689e+01],\n",
       "         [-1.7274e+01],\n",
       "         [-2.8006e+01],\n",
       "         [-2.8357e+01],\n",
       "         [-2.2596e+01],\n",
       "         [-1.9128e+01],\n",
       "         [-1.8241e+01],\n",
       "         [-1.8474e+01],\n",
       "         [-1.8759e+01],\n",
       "         [-1.8079e+01],\n",
       "         [-1.7898e+01],\n",
       "         [-1.7854e+01],\n",
       "         [-1.8626e+01],\n",
       "         [-1.7937e+01],\n",
       "         [-1.7783e+01],\n",
       "         [-1.7922e+01],\n",
       "         [-1.8144e+01],\n",
       "         [-1.8214e+01],\n",
       "         [-1.8192e+01],\n",
       "         [-1.7480e+01],\n",
       "         [-1.8345e+01],\n",
       "         [-1.8208e+01],\n",
       "         [-1.8118e+01],\n",
       "         [-1.8043e+01]],\n",
       "\n",
       "        [[-8.8334e+00],\n",
       "         [-3.1082e-03],\n",
       "         [-2.4370e-02],\n",
       "         [-8.4591e-04],\n",
       "         [-4.5165e-03],\n",
       "         [-2.5948e-04],\n",
       "         [-2.7577e+01],\n",
       "         [-8.0598e+00],\n",
       "         [-2.6333e+01],\n",
       "         [-2.3541e+01],\n",
       "         [-2.5298e+01],\n",
       "         [-1.9281e+01],\n",
       "         [-2.3504e+01],\n",
       "         [-1.9625e+01],\n",
       "         [-1.8931e+01],\n",
       "         [-2.0383e+01],\n",
       "         [-1.9986e+01],\n",
       "         [-1.9399e+01],\n",
       "         [-2.5851e+01],\n",
       "         [-2.0356e+01],\n",
       "         [-2.5355e+01],\n",
       "         [-1.9923e+01],\n",
       "         [-2.0178e+01],\n",
       "         [-2.2339e+01],\n",
       "         [-2.8468e+01],\n",
       "         [-2.8650e+01],\n",
       "         [-2.3151e+01],\n",
       "         [-2.0458e+01],\n",
       "         [-2.0796e+01],\n",
       "         [-2.4794e+01],\n",
       "         [-2.9090e+01],\n",
       "         [-2.8533e+01],\n",
       "         [-2.8608e+01],\n",
       "         [-2.7870e+01],\n",
       "         [-2.5586e+01],\n",
       "         [-2.0855e+01],\n",
       "         [-2.0357e+01],\n",
       "         [-2.0532e+01],\n",
       "         [-2.0607e+01],\n",
       "         [-2.0193e+01],\n",
       "         [-2.0278e+01],\n",
       "         [-2.0685e+01],\n",
       "         [-2.8509e+01],\n",
       "         [-2.9220e+01],\n",
       "         [-2.9310e+01],\n",
       "         [-2.9133e+01],\n",
       "         [-2.8551e+01],\n",
       "         [-2.8795e+01],\n",
       "         [-2.6573e+01],\n",
       "         [-2.0240e+01],\n",
       "         [-2.0128e+01],\n",
       "         [-2.7622e+01],\n",
       "         [-2.7099e+01],\n",
       "         [-2.6859e+01],\n",
       "         [-2.0069e+01],\n",
       "         [-2.7731e+01],\n",
       "         [-2.4372e+01],\n",
       "         [-2.6695e+01],\n",
       "         [-1.9634e+01],\n",
       "         [-2.0016e+01],\n",
       "         [-1.9557e+01],\n",
       "         [-2.0483e+01],\n",
       "         [-2.0913e+01],\n",
       "         [-2.7647e+01]],\n",
       "\n",
       "        [[-9.4318e+00],\n",
       "         [-2.7238e-02],\n",
       "         [-4.6606e-03],\n",
       "         [-1.3805e-01],\n",
       "         [-2.5097e+01],\n",
       "         [-9.1529e+00],\n",
       "         [-2.2190e+01],\n",
       "         [-2.1661e+01],\n",
       "         [-2.1899e+01],\n",
       "         [-2.1798e+01],\n",
       "         [-2.1952e+01],\n",
       "         [-2.1949e+01],\n",
       "         [-2.2241e+01],\n",
       "         [-2.1762e+01],\n",
       "         [-2.2026e+01],\n",
       "         [-2.1210e+01],\n",
       "         [-2.2072e+01],\n",
       "         [-2.1756e+01],\n",
       "         [-2.1265e+01],\n",
       "         [-2.1297e+01],\n",
       "         [-2.2411e+01],\n",
       "         [-2.1388e+01],\n",
       "         [-2.2278e+01],\n",
       "         [-2.4551e+01],\n",
       "         [-2.2252e+01],\n",
       "         [-2.1373e+01],\n",
       "         [-2.1692e+01],\n",
       "         [-2.1230e+01],\n",
       "         [-2.2249e+01],\n",
       "         [-2.2131e+01],\n",
       "         [-2.1719e+01],\n",
       "         [-2.8416e+01],\n",
       "         [-2.2662e+01],\n",
       "         [-2.1115e+01],\n",
       "         [-2.5482e+01],\n",
       "         [-2.2396e+01],\n",
       "         [-2.0472e+01],\n",
       "         [-2.1889e+01],\n",
       "         [-2.1175e+01],\n",
       "         [-1.9116e+01],\n",
       "         [-2.0981e+01],\n",
       "         [-2.8657e+01],\n",
       "         [-2.8724e+01],\n",
       "         [-2.2390e+01],\n",
       "         [-2.6068e+01],\n",
       "         [-2.1902e+01],\n",
       "         [-2.0157e+01],\n",
       "         [-2.7385e+01],\n",
       "         [-2.1095e+01],\n",
       "         [-2.0688e+01],\n",
       "         [-2.1670e+01],\n",
       "         [-2.6603e+01],\n",
       "         [-2.1634e+01],\n",
       "         [-2.1837e+01],\n",
       "         [-2.1351e+01],\n",
       "         [-2.1250e+01],\n",
       "         [-2.6620e+01],\n",
       "         [-2.2251e+01],\n",
       "         [-2.0959e+01],\n",
       "         [-2.0569e+01],\n",
       "         [-2.2091e+01],\n",
       "         [-2.2252e+01],\n",
       "         [-2.2014e+01],\n",
       "         [-2.1769e+01]],\n",
       "\n",
       "        [[-9.0732e+00],\n",
       "         [-8.7394e-03],\n",
       "         [-5.5703e-04],\n",
       "         [-4.3968e-01],\n",
       "         [-2.8028e-01],\n",
       "         [-3.5060e-03],\n",
       "         [-1.5308e-02],\n",
       "         [-1.2027e-03],\n",
       "         [-1.4755e-01],\n",
       "         [-2.5308e-03],\n",
       "         [-9.3109e-03],\n",
       "         [-7.4148e-03],\n",
       "         [-9.8754e-03],\n",
       "         [-5.2452e-06],\n",
       "         [-7.4072e+00],\n",
       "         [-1.8722e+01],\n",
       "         [-1.9121e+01],\n",
       "         [-1.8967e+01],\n",
       "         [-1.8118e+01],\n",
       "         [-1.9040e+01],\n",
       "         [-1.9155e+01],\n",
       "         [-1.8867e+01],\n",
       "         [-1.9211e+01],\n",
       "         [-1.9320e+01],\n",
       "         [-1.9141e+01],\n",
       "         [-1.8937e+01],\n",
       "         [-1.9236e+01],\n",
       "         [-1.9244e+01],\n",
       "         [-1.9246e+01],\n",
       "         [-1.9269e+01],\n",
       "         [-1.9572e+01],\n",
       "         [-1.9358e+01],\n",
       "         [-1.9010e+01],\n",
       "         [-1.8889e+01],\n",
       "         [-1.8491e+01],\n",
       "         [-1.9041e+01],\n",
       "         [-1.8749e+01],\n",
       "         [-1.8591e+01],\n",
       "         [-1.8513e+01],\n",
       "         [-1.8916e+01],\n",
       "         [-1.9263e+01],\n",
       "         [-1.8770e+01],\n",
       "         [-1.9695e+01],\n",
       "         [-1.8777e+01],\n",
       "         [-1.8389e+01],\n",
       "         [-1.8762e+01],\n",
       "         [-1.8422e+01],\n",
       "         [-1.8451e+01],\n",
       "         [-1.8547e+01],\n",
       "         [-1.7701e+01],\n",
       "         [-1.8878e+01],\n",
       "         [-1.8616e+01],\n",
       "         [-1.8794e+01],\n",
       "         [-1.8580e+01],\n",
       "         [-1.9074e+01],\n",
       "         [-1.9084e+01],\n",
       "         [-1.9149e+01],\n",
       "         [-1.8946e+01],\n",
       "         [-1.9829e+01],\n",
       "         [-1.8561e+01],\n",
       "         [-1.9144e+01],\n",
       "         [-1.9263e+01],\n",
       "         [-1.9638e+01],\n",
       "         [-1.8686e+01]]], device='cuda:0', grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f[torch.arange(input_ids.shape[0])[:, None], torch.arange(input_ids.shape[1]), input_ids][:, :, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6877070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = torch.nn.LogSoftmax(dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0c5f923c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'म पनि थुलो किताब पढ्न चाहन्छ । म र र र र र र र र रजपज र पनिपपपपप पनि पढ्नप ।पपपप र पनि पनिपपप पनि पनि् । । । ।ज्् र र रज र र र ।्प ।'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(torch.argmax(ls(v.logits)[1],dim=1)[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b1bc5b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 599, 10007, 3]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('नेपालिले')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74da5e43",
   "metadata": {},
   "source": [
    "# Functions to correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef2b1a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import BrillMoore\n",
    "import regex as re\n",
    "from utils import final_candidate_words, return_lexicon_dict\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "def words(text): \n",
    "    text = re.sub(r'[\\u0964]', r'\\u0020\\u0964\\u0020', text)\n",
    "    return re.findall(r'[\\u0900-\\u097F]+', text.lower())\n",
    "\n",
    "final_lexicon_dict = return_lexicon_dict()\n",
    "\n",
    "with open(os.path.join(notebook_dir, '..','models','bma_27dec.pickle'),'rb') as f:\n",
    "    bma = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77e0f540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_bm(sentence,candidate_sentence):\n",
    "    '''\n",
    "    Returns P(Possible Typo Sentence/Candidate Correct Sentence)\n",
    "    \n",
    "    Uses Naive approach to compute probability for sentence from individual words\n",
    "    \n",
    "    '''    \n",
    "    \n",
    "    prod = 1\n",
    "    for word,candidate_word in zip(sentence.split(),candidate_sentence):          \n",
    "        prod*= bma.likelihood(word,candidate_word)\n",
    "        #print(\"prod:\",prod)\n",
    "    return prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76db903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctize_entire_nn(sentence, model,p_lambda = 1,prior='transformer',trie = False,likelihood = 'default'):\n",
    "    \n",
    "    tokens = words(sentence)\n",
    "\n",
    "    candidates = []    \n",
    "    \n",
    "    #Forcing to limit the number of candidate sentences\n",
    "    for _ in tokens:\n",
    "        candidates.append(final_candidate_words(_,use_trie = trie,force = True))\n",
    "    \n",
    "    cs = list(itertools.product(*candidates))    \n",
    "    candidate_sentences = [' '.join(sent) for sent in cs]\n",
    "\n",
    "    if prior == 'transformer':\n",
    "               \n",
    "\n",
    "        t = tokenizer(sample_sentences,padding = 'max_length',max_length =max_length,truncation=True)\n",
    "    \n",
    "        ids = t['input_ids']\n",
    "        mask = t['attention_mask']\n",
    "        input_ids = torch.tensor(ids)\n",
    "        mask_ids = torch.tensor(mask)\n",
    "        v = model(input_ids.to(device),mask_ids.to(device))\n",
    "        f = ls(v.logits)\n",
    "        c = f[torch.arange(input_ids.shape[0])[:, None], torch.arange(input_ids.shape[1]), input_ids][:, :, None].squeeze(2)\n",
    "\n",
    "        candidate_probabilities = torch.sum((c*mask_ids.to(device))[1:],dim = 1)\n",
    "        \n",
    "        if likelihood=='default':\n",
    "            candidate_count = [len(_) for _ in candidates]  \n",
    "            sentences_probab_post=[(row*p_lambda) +\n",
    "                                   math.log(constant_distributive_likelihood(sentence,candidate_sentence,candidate_count)) \n",
    "                                   for row,candidate_sentence in zip(candidate_probabilities,cs)]\n",
    "        elif likelihood=='bm':\n",
    "            sentences_probab_post=[(row*p_lambda) + \n",
    "                                    math.log(likelihood_bm(sentence,candidate_sentence)) \n",
    "                                    for row,candidate_sentence in zip(candidate_probabilities,cs)]\n",
    "        sorted_index = torch.argsort(torch.tensor(sentences_probab_post))\n",
    "        sentences_probab_post_sorted = sorted(sentences_probab_post,reverse = True)\n",
    "        \n",
    "        return [candidate_sentences[int(k)].split() for k in torch.flip(sorted_index,dims=(0,))],sentences_probab_post_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a4d5b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctize_with_window_nn(sentence,model,window = 5,p_lambda = 1,prior = 'transformer',trie = False,likelihood = 'default'):\n",
    "    '''\n",
    "    \n",
    "    '''   \n",
    "    \n",
    "    tokens = words(sentence)\n",
    "    if len(tokens) <= window:\n",
    "#         print(correctize_entire_nn(sentence,model,p_lambda=p_lambda,prior = prior,trie = trie,likelihood = likelihood))\n",
    "        return [correctize_entire_nn(sentence,model,p_lambda=p_lambda,prior = prior,trie = trie,likelihood = likelihood)]\n",
    "    else:\n",
    "        windows = [tokens[n:window+n] for n in range(0,len(tokens),window-1) if window+n <len(tokens)-1]    \n",
    "        remaining = (window-1)*len(windows)\n",
    "        windows.append(tokens[remaining:])\n",
    "        corrects = []\n",
    "        for _ in windows:\n",
    "            d = correctize_entire_nn(' '.join(_),model,p_lambda=p_lambda,prior = prior,trie = trie,likelihood = likelihood)\n",
    "            corrects.append(d)\n",
    "#         print(corrects)\n",
    "        return corrects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a195b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_choices2(sample_sentences,model,p_lambda = 1,trie = False,model_type ='knlm' ,likelihood = 'default'):\n",
    "    \n",
    "    if model_type =='knlm':\n",
    "        d = correctize_with_window_knlm(sample_sentences,model,p_lambda =p_lambda,trie = trie,likelihood = likelihood)\n",
    "        window_candidates = []\n",
    "        window_probab = []\n",
    "        for window in d:\n",
    "            maxim = min(len(window[0]),10)\n",
    "            top_candidates = window[0][:maxim]\n",
    "            window_candidates.append(top_candidates)\n",
    "            window_probab.append(window[1][:maxim])\n",
    "        return window_candidates,window_probab\n",
    "    \n",
    "    if model_type == 'transformer':\n",
    "        d = correctize_with_window_nn(sample_sentences,model,p_lambda =p_lambda,trie = trie,likelihood = likelihood)\n",
    "        window_candidates = []\n",
    "        window_probab = []\n",
    "        for window in d:\n",
    "            maxim = min(len(window[0]),10)\n",
    "            top_candidates = window[0][:maxim]\n",
    "            window_candidates.append(top_candidates)\n",
    "            window_probab.append(window[1][:maxim])\n",
    "        return window_candidates,window_probab\n",
    "        \n",
    "def extract_choices(sample_sentences,model,p_lambda = 1,trie = False,likelihood = 'default',model_type = 'knlm'):\n",
    "    \n",
    "    \n",
    "    wc,wp = return_choices2(sample_sentences,model,p_lambda = p_lambda,trie = trie ,model_type = model_type,likelihood = likelihood)\n",
    "#     choices_list=[set() for i in range(len(sample_sentences.split())+1)]\n",
    "    choices_list=[[] for i in range(len(sample_sentences.split())+1)]\n",
    "#     print(len(choices_list))\n",
    "\n",
    "    const = 0\n",
    "    for _ in wc:\n",
    "        for sens in _:\n",
    "            for i,w in enumerate(sens):\n",
    "                index = i + const\n",
    "                if w not in choices_list[index]:\n",
    "                    choices_list[index].append(w)\n",
    "        const += len(wc[0][0])-1\n",
    "    if len(choices_list[len(choices_list)-1]) == 0:\n",
    "        return choices_list[:len(choices_list)-1]\n",
    "    return choices_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3711de2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['म'],\n",
       " ['पुस्तकालयमा'],\n",
       " ['ठुलो'],\n",
       " ['किताब', 'कतार', 'किटान'],\n",
       " ['पढ्न', 'पढ्ने', 'बढ्न', 'चढ्न', 'पढ्दा'],\n",
       " ['चाहन्छ', 'चाहन्छन्', 'चाहन्छु'],\n",
       " ['।', 'अ', 'ः', 'इ', 'आ']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_choices(sample_sentences[1],model=model,p_lambda = 0.135,trie = True,likelihood = 'bm',model_type = 'transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c61ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_choices(sample_sentences[2],model=model,p_lambda =0.135 ,trie = True,likelihood = 'bm',model_type = 'transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0ece0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'तर उस समयमा पनि स्वस्थ राजनैतिक वातावरनको अभावले गर्दा देश विकासतर्फ विशेष प्रगति हुन  सकेन।'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentences[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c1d8bb",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c395819",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = torch.nn.LogSoftmax(dim = 2)\n",
    "max_length = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18810a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval import gather_dataset,WER,word_accuracy,char_accuracy\n",
    "\n",
    "dataset_file = os.path.join(notebook_dir, '..','data','eval_data2.pic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a8da6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = gather_dataset(dataset_file)[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2aea7195",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_tokens = [words(t[0]) for t in dataset]\n",
    "error_tokens = [words(t[1]) for t in dataset]\n",
    "error_sentences = [t[1] for t in dataset] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a638b681",
   "metadata": {},
   "source": [
    "## BM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf72b3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "0.6  :  (0.3333333333333333, 14, 42) WER1:  0.2727272727272727 WER2:  0.35714285714285715\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "0.8  :  (0.3333333333333333, 14, 42) WER1:  0.2727272727272727 WER2:  0.35714285714285715\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "1.0  :  (0.3333333333333333, 14, 42) WER1:  0.2727272727272727 WER2:  0.35714285714285715\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "1.2000000000000002  :  (0.3333333333333333, 14, 42) WER1:  0.2727272727272727 WER2:  0.35714285714285715\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "1.4  :  (0.3333333333333333, 14, 42) WER1:  0.2727272727272727 WER2:  0.35714285714285715\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "1.6  :  (0.3333333333333333, 14, 42) WER1:  0.2727272727272727 WER2:  0.35714285714285715\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "1.8000000000000003  :  (0.3333333333333333, 14, 42) WER1:  0.2727272727272727 WER2:  0.35714285714285715\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "2.0  :  (0.3333333333333333, 14, 42) WER1:  0.2727272727272727 WER2:  0.35714285714285715\n",
      "0\n",
      "2\n",
      "4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#         word_accuracy(correct_tokens[:a],predicted_tokens[:a],error_tokens[:a])\u001b[39;00m\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m0.6\u001b[39m\u001b[38;5;241m+\u001b[39mGap\u001b[38;5;241m*\u001b[39mj,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m : \u001b[39m\u001b[38;5;124m'\u001b[39m,word_accuracy(correct_tokens[:a],predicted_tokens[:a],error_tokens[:a]),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWER1: \u001b[39m\u001b[38;5;124m'\u001b[39m,WER(correct_tokens[:a],error_tokens[:a] ),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWER2: \u001b[39m\u001b[38;5;124m'\u001b[39m,WER(correct_tokens[:a],predicted_tokens[:a] ))\n\u001b[1;32m---> 15\u001b[0m \u001b[43mfind_p_lambda\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror_sentences\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[27], line 7\u001b[0m, in \u001b[0;36mfind_p_lambda\u001b[1;34m(error_sentences)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i,s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(error_sentences[:a]):\n\u001b[1;32m----> 7\u001b[0m         c \u001b[38;5;241m=\u001b[39m \u001b[43mextract_choices\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mp_lambda\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.6\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mGap\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrie\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtransformer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m#     print(c)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m         c \u001b[38;5;241m=\u001b[39m [t[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m c]\n",
      "Cell \u001b[1;32mIn[19], line 28\u001b[0m, in \u001b[0;36mextract_choices\u001b[1;34m(sample_sentences, model, p_lambda, trie, likelihood, model_type)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_choices\u001b[39m(sample_sentences,model,p_lambda \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,trie \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,likelihood \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m,model_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknlm\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m---> 28\u001b[0m     wc,wp \u001b[38;5;241m=\u001b[39m \u001b[43mreturn_choices2\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_sentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mp_lambda\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mp_lambda\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrie\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrie\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#     choices_list=[set() for i in range(len(sample_sentences.split())+1)]\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     choices_list\u001b[38;5;241m=\u001b[39m[[] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(sample_sentences\u001b[38;5;241m.\u001b[39msplit())\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n",
      "Cell \u001b[1;32mIn[19], line 15\u001b[0m, in \u001b[0;36mreturn_choices2\u001b[1;34m(sample_sentences, model, p_lambda, trie, model_type, likelihood)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m window_candidates,window_probab\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformer\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 15\u001b[0m     d \u001b[38;5;241m=\u001b[39m \u001b[43mcorrectize_with_window_nn\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_sentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mp_lambda\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp_lambda\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrie\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrie\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     window_candidates \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     17\u001b[0m     window_probab \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[18], line 16\u001b[0m, in \u001b[0;36mcorrectize_with_window_nn\u001b[1;34m(sentence, model, window, p_lambda, prior, trie, likelihood)\u001b[0m\n\u001b[0;32m     14\u001b[0m         corrects \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m windows:\n\u001b[1;32m---> 16\u001b[0m             d \u001b[38;5;241m=\u001b[39m \u001b[43mcorrectize_entire_nn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mp_lambda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp_lambda\u001b[49m\u001b[43m,\u001b[49m\u001b[43mprior\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprior\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrie\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrie\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m             corrects\u001b[38;5;241m.\u001b[39mappend(d)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#         print(corrects)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 9\u001b[0m, in \u001b[0;36mcorrectize_entire_nn\u001b[1;34m(sentence, model, p_lambda, prior, trie, likelihood)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m#Forcing to limit the number of candidate sentences\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tokens:\n\u001b[1;32m----> 9\u001b[0m         candidates\u001b[38;5;241m.\u001b[39mappend(\u001b[43mfinal_candidate_words\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43muse_trie\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrie\u001b[49m\u001b[43m,\u001b[49m\u001b[43mforce\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#     candidate_sentences = list(itertools.product(*candidates))[:]\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     cs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(itertools\u001b[38;5;241m.\u001b[39mproduct(\u001b[38;5;241m*\u001b[39mcandidates))    \n",
      "File \u001b[1;32mF:\\SpellChecker\\experiments\\checker\\utils.py:141\u001b[0m, in \u001b[0;36mfinal_candidate_words\u001b[1;34m(word, minimum, top, start_depth, force, use_trie, time)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m    139\u001b[0m     s \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 141\u001b[0m c \u001b[38;5;241m=\u001b[39m candidate_words(word,minimum \u001b[38;5;241m=\u001b[39m minimum,start_depth \u001b[38;5;241m=\u001b[39m start_depth) \u001b[38;5;28;01mif\u001b[39;00m use_trie \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mcandidate_words_trie\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43mminimum\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mminimum\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstart_depth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstart_depth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(c) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m6\u001b[39m:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time:\n",
      "File \u001b[1;32mF:\\SpellChecker\\experiments\\checker\\utils.py:122\u001b[0m, in \u001b[0;36mcandidate_words_trie\u001b[1;34m(word, minimum, start_depth, edit_probabs)\u001b[0m\n\u001b[0;32m    118\u001b[0m             c,c_ \u001b[38;5;241m=\u001b[39m check_distance_trie(word, depth \u001b[38;5;241m=\u001b[39m start_depth\u001b[38;5;241m+\u001b[39mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,edit_distance \u001b[38;5;241m=\u001b[39m ed1,candidates \u001b[38;5;241m=\u001b[39m c)\n\u001b[0;32m    120\u001b[0m \u001b[38;5;66;03m#If word length is more than 3 than use edit distance of 2 or less\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:        \n\u001b[1;32m--> 122\u001b[0m     c,c_ \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_distance_trie\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstart_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43medit_distance\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43med2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcandidates\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(trie_depth)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m c_ \u001b[38;5;241m<\u001b[39m minimum:\n\u001b[0;32m    125\u001b[0m             \u001b[38;5;66;03m#print(\"Entered depth, \",i+1)\u001b[39;00m\n",
      "File \u001b[1;32mF:\\SpellChecker\\experiments\\checker\\utils.py:71\u001b[0m, in \u001b[0;36mcheck_distance_trie\u001b[1;34m(w, depth, edit_distance, candidates)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_distance_trie\u001b[39m(w, depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,edit_distance \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m,candidates \u001b[38;5;241m=\u001b[39m []):\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m     candidates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mtrie_depth\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43medit_distance\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (candidates,\u001b[38;5;28mlen\u001b[39m(candidates))\n",
      "File \u001b[1;32mF:\\SpellChecker\\experiments\\Trie.py:38\u001b[0m, in \u001b[0;36mTrie.search\u001b[1;34m(self, word, max_distance)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m char, node \u001b[38;5;129;01min\u001b[39;00m current\u001b[38;5;241m.\u001b[39mchildren\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     37\u001b[0m     new_word \u001b[38;5;241m=\u001b[39m current_word \u001b[38;5;241m+\u001b[39m char\n\u001b[1;32m---> 38\u001b[0m     new_distance \u001b[38;5;241m=\u001b[39m \u001b[43mtextdistance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlevenshtein\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_word\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m new_distance \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mabs\u001b[39m(\u001b[38;5;28mlen\u001b[39m(new_word) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(word)))\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m     40\u001b[0m         queue\u001b[38;5;241m.\u001b[39mappend((node, new_word, new_distance))\n",
      "File \u001b[1;32mF:\\SpellChecker\\venv\\lib\\site-packages\\textdistance\\algorithms\\base.py:34\u001b[0m, in \u001b[0;36mBase.distance\u001b[1;34m(self, *sequences)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdistance\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39msequences: Sequence[\u001b[38;5;28mobject\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;124;03m\"\"\"Get distance between sequences\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msequences\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\SpellChecker\\venv\\lib\\site-packages\\textdistance\\algorithms\\edit_based.py:137\u001b[0m, in \u001b[0;36mLevenshtein.__call__\u001b[1;34m(self, s1, s2)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cycled\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\SpellChecker\\venv\\lib\\site-packages\\textdistance\\algorithms\\edit_based.py:115\u001b[0m, in \u001b[0;36mLevenshtein._cycled\u001b[1;34m(self, s1, s2)\u001b[0m\n\u001b[0;32m    113\u001b[0m cur: Any\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numpy:\n\u001b[1;32m--> 115\u001b[0m     cur \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m     cur \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(cols)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Gap = 0.2\n",
    "a = 10\n",
    "def find_p_lambda(error_sentences):\n",
    "    predicted_tokens = []\n",
    "    for j in range(10):\n",
    "        for i,s in enumerate(error_sentences[:a]):\n",
    "            c = extract_choices(s,model=model,p_lambda =0.6 + Gap*j,trie = True,likelihood = 'bm',model_type = 'transformer')\n",
    "        #     print(c)\n",
    "            c = [t[0] for t in c]\n",
    "            predicted_tokens.append(c)\n",
    "            if i%2 == 0:\n",
    "                print(i)\n",
    "#         word_accuracy(correct_tokens[:a],predicted_tokens[:a],error_tokens[:a])\n",
    "        print(0.6+Gap*j,' : ',word_accuracy(correct_tokens[:a],predicted_tokens[:a],error_tokens[:a]),'WER1: ',WER(correct_tokens[:a],error_tokens[:a] ),'WER2: ',WER(correct_tokens[:a],predicted_tokens[:a] ))\n",
    "find_p_lambda(error_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7ec606a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "16\n",
      "18\n",
      "20\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "30\n",
      "32\n",
      "34\n",
      "36\n",
      "38\n",
      "40\n",
      "42\n",
      "44\n",
      "46\n",
      "48\n",
      "50\n",
      "52\n",
      "54\n",
      "56\n",
      "58\n",
      "60\n",
      "62\n",
      "64\n",
      "66\n",
      "68\n",
      "70\n",
      "72\n",
      "74\n",
      "76\n",
      "78\n",
      "80\n",
      "82\n",
      "84\n",
      "86\n",
      "88\n",
      "90\n",
      "92\n",
      "94\n",
      "96\n",
      "98\n",
      "100\n",
      "102\n",
      "104\n",
      "106\n",
      "108\n",
      "110\n",
      "112\n",
      "114\n",
      "116\n",
      "118\n",
      "120\n",
      "122\n",
      "124\n",
      "126\n",
      "128\n",
      "130\n",
      "132\n",
      "134\n",
      "136\n",
      "138\n",
      "140\n",
      "142\n",
      "144\n",
      "146\n",
      "148\n",
      "150\n",
      "152\n",
      "154\n",
      "156\n",
      "158\n",
      "160\n",
      "162\n",
      "164\n",
      "166\n",
      "168\n",
      "170\n",
      "172\n",
      "174\n",
      "176\n",
      "178\n",
      "180\n",
      "182\n",
      "184\n",
      "186\n",
      "188\n",
      "190\n",
      "192\n",
      "194\n",
      "196\n",
      "198\n",
      "200\n",
      "202\n",
      "204\n",
      "206\n",
      "208\n",
      "210\n",
      "212\n",
      "214\n",
      "216\n",
      "218\n",
      "220\n",
      "222\n",
      "224\n",
      "226\n",
      "228\n",
      "230\n",
      "232\n",
      "234\n",
      "236\n",
      "238\n",
      "240\n",
      "242\n",
      "244\n",
      "246\n",
      "248\n",
      "250\n",
      "252\n",
      "254\n",
      "256\n",
      "258\n",
      "260\n",
      "262\n",
      "264\n",
      "266\n",
      "268\n",
      "270\n",
      "272\n",
      "274\n",
      "276\n",
      "278\n",
      "280\n",
      "282\n",
      "284\n",
      "286\n",
      "288\n",
      "290\n",
      "292\n",
      "294\n",
      "296\n",
      "298\n",
      "300\n",
      "302\n",
      "304\n",
      "306\n",
      "308\n",
      "310\n",
      "312\n",
      "314\n",
      "316\n",
      "318\n",
      "320\n",
      "322\n",
      "0.2727272727272727 0.35714285714285715 (0.3333333333333333, 14, 42) (0.3958333333333333, 19, 48)\n",
      "324\n",
      "326\n",
      "328\n",
      "330\n",
      "332\n",
      "334\n",
      "336\n",
      "338\n",
      "340\n",
      "342\n",
      "344\n",
      "346\n",
      "348\n",
      "350\n",
      "352\n",
      "354\n",
      "356\n",
      "358\n",
      "360\n",
      "362\n",
      "364\n",
      "366\n",
      "368\n",
      "370\n",
      "372\n",
      "374\n",
      "376\n",
      "378\n",
      "380\n",
      "382\n",
      "384\n",
      "386\n",
      "388\n",
      "390\n",
      "392\n",
      "394\n",
      "396\n",
      "398\n"
     ]
    }
   ],
   "source": [
    "predicted_tokens = []\n",
    "for i,s in enumerate(error_sentences):\n",
    "    c = extract_choices(s,model=model,p_lambda = 0.6,trie = True,likelihood = 'bm',model_type = 'transformer')\n",
    "#     print(c)\n",
    "    c = [t[0] for t in c]\n",
    "    predicted_tokens.append(c)\n",
    "    if i%2 == 0:\n",
    "        print(i)\n",
    "    if i==323:\n",
    "        print(WER(correct_tokens[:a],error_tokens[:a] ),WER(correct_tokens[:a],predicted_tokens[:a] ),word_accuracy(correct_tokens[:a],predicted_tokens[:a],error_tokens[:a]),char_accuracy(correct_tokens[:a],predicted_tokens[:a],error_tokens[:a]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a764da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d9aaace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.25042111173498033, 0.30226464533033875)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 324\n",
    "WER(correct_tokens[:a],error_tokens[:a] ),WER(correct_tokens[:a],predicted_tokens[:a] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f0b43c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3333333333333333, 446, 1338)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_accuracy(correct_tokens[:a],predicted_tokens[:a],error_tokens[:a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4bb25f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4168781725888325, 657, 1576)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_accuracy(correct_tokens[:a],predicted_tokens[:a],error_tokens[:a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "365d8294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f917704",
   "metadata": {},
   "source": [
    "## CD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b499a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.65\n",
    "def constant_distributive_likelihood(sentence,candidate_sentence,candidate_count):\n",
    "    prod = 1    \n",
    "    i = 0\n",
    "    #print(sentence.split(),candidate_sentence)\n",
    "    \n",
    "    for word,candidate_word in zip(sentence.split(),candidate_sentence):        \n",
    "        if word==candidate_word:\n",
    "            prod*= alpha\n",
    "        else:\n",
    "            N = candidate_count[i]\n",
    "            prod*= (1-alpha)/N\n",
    "        i+=1\n",
    "    return prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6caad676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "0.0  :  (0.21428571428571427, 9, 42) WER1:  0.2727272727272727 WER2:  0.33116883116883117\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "0.2  :  (0.23809523809523808, 10, 42) WER1:  0.2727272727272727 WER2:  0.33766233766233766\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "0.4  :  (0.30952380952380953, 13, 42) WER1:  0.2727272727272727 WER2:  0.3246753246753247\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "0.6000000000000001  :  (0.2619047619047619, 11, 42) WER1:  0.2727272727272727 WER2:  0.37012987012987014\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "0.8  :  (0.2619047619047619, 11, 42) WER1:  0.2727272727272727 WER2:  0.37012987012987014\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "1.0  :  (0.2619047619047619, 11, 42) WER1:  0.2727272727272727 WER2:  0.37012987012987014\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "1.2000000000000002  :  (0.30952380952380953, 13, 42) WER1:  0.2727272727272727 WER2:  0.45454545454545453\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "1.4000000000000001  :  (0.30952380952380953, 13, 42) WER1:  0.2727272727272727 WER2:  0.461038961038961\n"
     ]
    }
   ],
   "source": [
    "Gap = 0.2\n",
    "a = 10\n",
    "def find_p_lambda(error_sentences):\n",
    "    \n",
    "    for j in range(8):\n",
    "        predicted_tokens = []\n",
    "        for i,s in enumerate(error_sentences[:a]):\n",
    "            c = extract_choices(s,model=model,p_lambda = Gap*j,trie = True,likelihood = 'default',model_type = 'transformer')\n",
    "        #     print(c)\n",
    "            c = [t[0] for t in c]\n",
    "            predicted_tokens.append(c)\n",
    "            if i%2 == 0:\n",
    "                print(i)\n",
    "#         word_accuracy(correct_tokens[:a],predicted_tokens[:a],error_tokens[:a])\n",
    "        print(Gap*j,' : ',word_accuracy(correct_tokens[:a],predicted_tokens[:a],error_tokens[:a]),'WER1: ',WER(correct_tokens[:a],error_tokens[:a] ),'WER2: ',WER(correct_tokens[:a],predicted_tokens[:a] ))\n",
    "find_p_lambda(error_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6e9f2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "16\n",
      "18\n",
      "20\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "30\n",
      "32\n",
      "34\n",
      "36\n",
      "38\n",
      "40\n",
      "42\n",
      "44\n",
      "46\n",
      "48\n",
      "50\n",
      "52\n",
      "54\n",
      "56\n",
      "58\n",
      "60\n",
      "62\n",
      "64\n",
      "66\n",
      "68\n",
      "70\n",
      "72\n",
      "74\n",
      "76\n",
      "78\n",
      "80\n",
      "82\n",
      "84\n",
      "86\n",
      "88\n",
      "90\n",
      "92\n",
      "94\n",
      "96\n",
      "98\n",
      "100\n",
      "102\n",
      "104\n",
      "106\n",
      "108\n",
      "110\n",
      "112\n",
      "114\n",
      "116\n",
      "118\n",
      "120\n",
      "122\n",
      "124\n",
      "126\n",
      "128\n",
      "130\n",
      "132\n",
      "134\n",
      "136\n",
      "138\n",
      "140\n",
      "142\n",
      "144\n",
      "146\n",
      "148\n",
      "150\n",
      "152\n",
      "154\n",
      "156\n",
      "158\n",
      "160\n",
      "162\n",
      "164\n",
      "166\n",
      "168\n",
      "170\n",
      "172\n",
      "174\n",
      "176\n",
      "178\n",
      "180\n",
      "182\n",
      "184\n",
      "186\n",
      "188\n",
      "190\n",
      "192\n",
      "194\n",
      "196\n",
      "198\n",
      "200\n",
      "202\n",
      "204\n",
      "206\n",
      "208\n",
      "210\n",
      "212\n",
      "214\n",
      "216\n",
      "218\n",
      "220\n",
      "222\n",
      "224\n",
      "226\n",
      "228\n",
      "230\n",
      "232\n",
      "234\n",
      "236\n",
      "238\n",
      "240\n",
      "242\n",
      "244\n",
      "246\n",
      "248\n",
      "250\n",
      "252\n",
      "254\n",
      "256\n",
      "258\n",
      "260\n",
      "262\n",
      "264\n",
      "266\n",
      "268\n",
      "270\n",
      "272\n",
      "274\n",
      "276\n",
      "278\n",
      "280\n",
      "282\n",
      "284\n",
      "286\n",
      "288\n",
      "290\n",
      "292\n",
      "294\n",
      "296\n",
      "298\n",
      "300\n",
      "302\n",
      "304\n",
      "306\n",
      "308\n",
      "310\n",
      "312\n",
      "314\n",
      "316\n",
      "318\n",
      "320\n",
      "322\n",
      "0.2727272727272727 0.3246753246753247 (0.30952380952380953, 13, 42) (0.3958333333333333, 19, 48)\n",
      "324\n",
      "326\n",
      "328\n",
      "330\n",
      "332\n",
      "334\n",
      "336\n",
      "338\n",
      "340\n",
      "342\n",
      "344\n",
      "346\n",
      "348\n",
      "350\n",
      "352\n",
      "354\n",
      "356\n",
      "358\n",
      "360\n",
      "362\n",
      "364\n",
      "366\n",
      "368\n",
      "370\n",
      "372\n",
      "374\n",
      "376\n",
      "378\n",
      "380\n",
      "382\n",
      "384\n",
      "386\n",
      "388\n",
      "390\n",
      "392\n",
      "394\n",
      "396\n",
      "398\n"
     ]
    }
   ],
   "source": [
    "predicted_tokens = []\n",
    "for i,s in enumerate(error_sentences):\n",
    "    c = extract_choices(s,model=model,p_lambda = 0.4,trie = True,likelihood = 'default',model_type = 'transformer')\n",
    "#     print(c)\n",
    "    c = [t[0] for t in c]\n",
    "    torch.cuda.empty_cache()\n",
    "    predicted_tokens.append(c)\n",
    "    if i%2 == 0:\n",
    "        print(i)\n",
    "    if i==323:\n",
    "        print(WER(correct_tokens[:a],error_tokens[:a] ),WER(correct_tokens[:a],predicted_tokens[:a] ),word_accuracy(correct_tokens[:a],predicted_tokens[:a],error_tokens[:a]),char_accuracy(correct_tokens[:a],predicted_tokens[:a],error_tokens[:a]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac69392a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.25042111173498033, 0.29421673217293653)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 324\n",
    "WER(correct_tokens[:a],error_tokens[:a] ),WER(correct_tokens[:a],predicted_tokens[:a] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19cc0882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2982062780269058, 399, 1338)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_accuracy(correct_tokens[:a],predicted_tokens[:a],error_tokens[:a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81c358f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4073604060913706, 642, 1576)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_accuracy(correct_tokens[:a],predicted_tokens[:a],error_tokens[:a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92be597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
