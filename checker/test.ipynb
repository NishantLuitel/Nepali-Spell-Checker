{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "368d5764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import final_candidate_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4da6abf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "767f6df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['पुस्तकालयबाट', 'पुस्तकलयबाटे']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_candidate_words('पुस्तकलयबाटे',use_trie = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b702af20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['पुस्तकालयबाट', 'पुस्तकलयबाटे']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_candidate_words('पुस्तकलयबाटे')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c98c720c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ठुलो', 'ठूलो', 'थुलो', 'ठुला', 'थलो', 'धुलो', 'धूलो']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_candidate_words('थुलो')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90a9d855",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentences = ['हरेक सेपालीले नेपामको संविधानक पालना गर्नुपर्छ ।' ,\n",
    "                    'म पुस्तकलयबाटे थुलो किताब पढ्न चाहन्छु ।',\n",
    "                    'तर उस समयमा पनि स्वस्थ राजनैतिक वातावरणको अभावले गर्दा देश विकासतर्फ विशेष प्रगति हुन  सकेन।',\n",
    "                   'नेपालमा आधुनिक रुपमा आर्थक विकाससम्बन्धी कार्यरू प्रारम्भ भएको हालै मात्र हो।',\n",
    "                   'हार धुनुहोस् र स्वास्थ जीवन जिउनुहोस्।',\n",
    "                   'जब प्रवीधिहरू एकीकृत हुन सूरु गर्छन् अर्थतन्त्र तथ सँस्कृति पनि निश्चितरूपमा विस्तारै एकीकृत हुने छ।',\n",
    "                   'उद्देयहरुमा पनि कुनै एक उद्देश्य पूर्ति नहुँदै अर्को नयाँ  उद्देश्यको रुपमा लिइने परम्परा बस्यो।',\n",
    "                   'लगानीकर्ताहरूको धयान तुरुन्त फेरियो , व्यापारीहरूले वताए ।',\n",
    "                    'अति धेरै हिज्जे गलती भएका शब्दहरू । तपाईँले टाइप गर्दा हिज्जे जाँच अक्षम पारयो ।',\n",
    "                    'लामो'\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce70d0a",
   "metadata": {},
   "source": [
    "# Testing with Knesner ney Language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca3dfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from corrector import extract_choices,return_choices2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea39993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('models/saved_model_knlm2','rb') as inputfile:\n",
    "    kn_lm2 = pickle.load(inputfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76cb2223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['अति', 'ति', 'अनि', 'अलि', 'यति'],\n",
       " ['धेरै'],\n",
       " ['हिज्जे'],\n",
       " ['गलत'],\n",
       " ['भएको', 'भएका'],\n",
       " ['शब्दहरू', 'शब्दहरु'],\n",
       " ['।'],\n",
       " ['तपाईंले', 'तपाईँले'],\n",
       " ['लाइक', 'पाप', 'टाइप', 'पाइप', 'टाइम'],\n",
       " ['गर्दा', 'गर्दै'],\n",
       " ['हिज्जे', 'हिड्ने'],\n",
       " ['जाँच', 'पाँच'],\n",
       " ['अक्षम', 'कक्षमा', 'अक्षय', 'अक्षर', 'सक्षम', 'पक्षमा'],\n",
       " ['पारयो', 'पायो', 'पाइयो', 'पारा', 'परको', 'पारस'],\n",
       " ['।'],\n",
       " []]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_choices(sample_sentences[8],model=kn_lm2,p_lambda = 0.3,trie = True,likelihood = 'bm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29a2d01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['म'],\n",
       " ['पुस्तकलयबाटे', 'पुस्तकालयबाट'],\n",
       " ['थुलो', 'ठुलो', 'धूलो', 'ठूलो', 'धुलो', 'थलो', 'ठुला'],\n",
       " ['किताब', 'पिसाब', 'हिसाब'],\n",
       " ['पढ्न'],\n",
       " ['चाहन्छु', 'चाहिन्छ', 'चाहन्छन्', 'चाहन्थे', 'चाहन्छौं', 'चाहन्छ'],\n",
       " ['।', 'ई', 'ओ', 'ः', 'अ'],\n",
       " []]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_choices(sample_sentences[1],model=kn_lm2,p_lambda = 0.0,trie = True,likelihood = 'default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fda277aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc,wp = return_choices2(sample_sentences[2],model=kn_lm2,p_lambda = 0.3,trie = True,likelihood = 'bm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57618c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('तर', 'आस', 'समयमा', 'पनि', 'स्वस्थ'),\n",
       "  ('तर', 'उप', 'समयमा', 'पनि', 'स्वस्थ'),\n",
       "  ('तर', 'उस', 'समयमा', 'पनि', 'स्वस्थ'),\n",
       "  ('तर', 'स', 'समयमा', 'पनि', 'स्वस्थ'),\n",
       "  ('कर', 'उस', 'समयमा', 'पनि', 'स्वस्थ'),\n",
       "  ('तार', 'उस', 'समयमा', 'पनि', 'स्वस्थ'),\n",
       "  ('तर', 'आस', 'समयको', 'पनि', 'स्वस्थ'),\n",
       "  ('तर', 'आस', 'सहरमा', 'पनि', 'स्वस्थ'),\n",
       "  ('पर', 'स', 'समयमा', 'पनि', 'स्वस्थ'),\n",
       "  ('तर', 'आस', 'समयमा', 'पनि', 'अस्वस्थ')],\n",
       " [('स्वस्थ', 'राजनीतिक', 'वातावरणको', 'अभावले', 'गर्दा'),\n",
       "  ('अस्वस्थ', 'राजनीतिक', 'वातावरणको', 'अभावले', 'गर्दा'),\n",
       "  ('स्वस्थ', 'राजनैतिक', 'वातावरणको', 'अभावले', 'गर्दा'),\n",
       "  ('स्वस्थ', 'राजनैतिक', 'वातावरणमा', 'अभावले', 'गर्दा'),\n",
       "  ('अस्वस्थ', 'राजनीति', 'वातावरणको', 'अभावले', 'गर्दा'),\n",
       "  ('स्वस्थ', 'राजनीतिक', 'वातावरणमा', 'अभावले', 'गर्दा'),\n",
       "  ('स्वस्थ', 'राजनीतिक', 'वातावरणको', 'अभावमा', 'गर्दा'),\n",
       "  ('स्वस्थ', 'राजनीतिक', 'वातावरणको', 'अभावले', 'पर्दा'),\n",
       "  ('स्वस्थ', 'राजनीतिक', 'वातावरणको', 'अभावले', 'गर्न'),\n",
       "  ('अस्वस्थ', 'राजनीतिका', 'वातावरणको', 'अभावले', 'गर्दा')],\n",
       " [('गर्दा', 'देश', 'विकासतर्फ', 'विशेष', 'प्रगति'),\n",
       "  ('गर्दा', 'देश', 'विकासतर्फ', 'विशेष', 'प्रति'),\n",
       "  ('पर्दा', 'देश', 'विकासतर्फ', 'विशेष', 'प्रगति'),\n",
       "  ('गर्दै', 'देश', 'विकासतर्फ', 'विशेष', 'प्रगति'),\n",
       "  ('गर्दा', 'देश', 'विकासतर्फ', 'विशेष', 'प्रावि'),\n",
       "  ('गर्दा', 'देश', 'विकासतर्फ', 'विशेष', 'प्रालि'),\n",
       "  ('पर्दा', 'देश', 'विकासतर्फ', 'विशेष', 'प्रति'),\n",
       "  ('गर्दै', 'देश', 'विकासतर्फ', 'विशेष', 'प्रति'),\n",
       "  ('गर्दा', 'देश', 'विकासतर्फ', 'विशेष', 'प्रगतिको'),\n",
       "  ('गर्दा', 'दश', 'विकासतर्फ', 'विशेष', 'प्रगति')],\n",
       " [('प्रगति', 'हुन', 'सकेन', '।'),\n",
       "  ('प्रगति', 'हुन', 'सकेनन्', '।'),\n",
       "  ('प्रगति', 'हुने', 'सकेन', '।'),\n",
       "  ('प्रगति', 'हुन', 'सकिन', '।'),\n",
       "  ('प्रगति', 'हुन', 'सकेर', '।'),\n",
       "  ('प्रगति', 'हुन', 'सकेका', '।'),\n",
       "  ('प्रगति', 'हुनै', 'सकेन', '।'),\n",
       "  ('प्रगति', 'हुन', 'सकेमा', '।'),\n",
       "  ('प्रगति', 'हुन', 'सक्न', '।'),\n",
       "  ('प्रावि', 'हुन्', 'सकेन', '।')]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c31100a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([('तर', 'आस', 'समयमा', 'पनि', 'स्वस्थ'),\n",
       "   ('तर', 'उप', 'समयमा', 'पनि', 'स्वस्थ'),\n",
       "   ('तर', 'उस', 'समयमा', 'पनि', 'स्वस्थ'),\n",
       "   ('तर', 'स', 'समयमा', 'पनि', 'स्वस्थ'),\n",
       "   ('कर', 'उस', 'समयमा', 'पनि', 'स्वस्थ'),\n",
       "   ('तार', 'उस', 'समयमा', 'पनि', 'स्वस्थ'),\n",
       "   ('तर', 'आस', 'समयको', 'पनि', 'स्वस्थ'),\n",
       "   ('तर', 'आस', 'सहरमा', 'पनि', 'स्वस्थ'),\n",
       "   ('पर', 'स', 'समयमा', 'पनि', 'स्वस्थ'),\n",
       "   ('तर', 'आस', 'समयमा', 'पनि', 'अस्वस्थ')],\n",
       "  [-46.05453056303696,\n",
       "   -46.44032601243608,\n",
       "   -48.11849540168839,\n",
       "   -48.93666063888338,\n",
       "   -49.32341562437037,\n",
       "   -49.91554247405139,\n",
       "   -50.00966664269788,\n",
       "   -50.014672315846965,\n",
       "   -50.05962883299812,\n",
       "   -50.08154654631848]),\n",
       " ([('स्वस्थ', 'राजनीतिक', 'वातावरणको', 'अभावले', 'गर्दा'),\n",
       "   ('अस्वस्थ', 'राजनीतिक', 'वातावरणको', 'अभावले', 'गर्दा'),\n",
       "   ('स्वस्थ', 'राजनैतिक', 'वातावरणको', 'अभावले', 'गर्दा'),\n",
       "   ('स्वस्थ', 'राजनैतिक', 'वातावरणमा', 'अभावले', 'गर्दा'),\n",
       "   ('अस्वस्थ', 'राजनीति', 'वातावरणको', 'अभावले', 'गर्दा'),\n",
       "   ('स्वस्थ', 'राजनीतिक', 'वातावरणमा', 'अभावले', 'गर्दा'),\n",
       "   ('स्वस्थ', 'राजनीतिक', 'वातावरणको', 'अभावमा', 'गर्दा'),\n",
       "   ('स्वस्थ', 'राजनीतिक', 'वातावरणको', 'अभावले', 'पर्दा'),\n",
       "   ('स्वस्थ', 'राजनीतिक', 'वातावरणको', 'अभावले', 'गर्न'),\n",
       "   ('अस्वस्थ', 'राजनीतिका', 'वातावरणको', 'अभावले', 'गर्दा')],\n",
       "  [-31.725204000997167,\n",
       "   -35.444468733411476,\n",
       "   -37.441040644096404,\n",
       "   -43.137770824123905,\n",
       "   -43.42443959133735,\n",
       "   -44.44313019292074,\n",
       "   -44.483812985745054,\n",
       "   -44.64325848689029,\n",
       "   -44.74891903281994,\n",
       "   -45.156171299061704]),\n",
       " ([('गर्दा', 'देश', 'विकासतर्फ', 'विशेष', 'प्रगति'),\n",
       "   ('गर्दा', 'देश', 'विकासतर्फ', 'विशेष', 'प्रति'),\n",
       "   ('पर्दा', 'देश', 'विकासतर्फ', 'विशेष', 'प्रगति'),\n",
       "   ('गर्दै', 'देश', 'विकासतर्फ', 'विशेष', 'प्रगति'),\n",
       "   ('गर्दा', 'देश', 'विकासतर्फ', 'विशेष', 'प्रावि'),\n",
       "   ('गर्दा', 'देश', 'विकासतर्फ', 'विशेष', 'प्रालि'),\n",
       "   ('पर्दा', 'देश', 'विकासतर्फ', 'विशेष', 'प्रति'),\n",
       "   ('गर्दै', 'देश', 'विकासतर्फ', 'विशेष', 'प्रति'),\n",
       "   ('गर्दा', 'देश', 'विकासतर्फ', 'विशेष', 'प्रगतिको'),\n",
       "   ('गर्दा', 'दश', 'विकासतर्फ', 'विशेष', 'प्रगति')],\n",
       "  [-39.24765666042136,\n",
       "   -42.13395509292989,\n",
       "   -42.408248539396084,\n",
       "   -44.49890156063423,\n",
       "   -44.994664454613584,\n",
       "   -45.169467178993514,\n",
       "   -45.29454697190461,\n",
       "   -47.38519999314276,\n",
       "   -47.6838943953378,\n",
       "   -48.15261809103687]),\n",
       " ([('प्रगति', 'हुन', 'सकेन', '।'),\n",
       "   ('प्रगति', 'हुन', 'सकेनन्', '।'),\n",
       "   ('प्रगति', 'हुने', 'सकेन', '।'),\n",
       "   ('प्रगति', 'हुन', 'सकिन', '।'),\n",
       "   ('प्रगति', 'हुन', 'सकेर', '।'),\n",
       "   ('प्रगति', 'हुन', 'सकेका', '।'),\n",
       "   ('प्रगति', 'हुनै', 'सकेन', '।'),\n",
       "   ('प्रगति', 'हुन', 'सकेमा', '।'),\n",
       "   ('प्रगति', 'हुन', 'सक्न', '।'),\n",
       "   ('प्रावि', 'हुन्', 'सकेन', '।')],\n",
       "  [-18.236764168780894,\n",
       "   -23.68679108029731,\n",
       "   -24.07317267754587,\n",
       "   -24.31110946168931,\n",
       "   -25.536151862415913,\n",
       "   -25.80169873310247,\n",
       "   -26.512707904024385,\n",
       "   -27.449325658901678,\n",
       "   -28.543898966399198,\n",
       "   -28.731586653404122])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(wc,wp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf8f90a",
   "metadata": {},
   "source": [
    "# Testing with transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ef2f89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db39737b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "393082b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\SpellChecker\\venv\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "from transformer import model\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a2b002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from corrector import extract_choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6049cef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('models/transformer_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3c33165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from corrector import correctize_with_window_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c85dd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from corrector import correctize_with_window_nn_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b431570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from corrector import transformer_probab_final_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d528eed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from corrector import correct_current_word,extract_choices_word,autocorrect_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6beef107",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentences = ['हरेक सेपालीले नेपामको संविधानक पालना गर्नुपर्छ ।' ,\n",
    "                    'म पुस्तकलयबाटे थुलो किताब पढ्न चाहन्छ ।',\n",
    "                    'तर उस समयमा पनि स्वस्थ राजनैतिक वातावरनको अभावले गर्दा देश विकासतर्फ विशेष प्रगति हुन  सकेन।',\n",
    "                   'नेपालमा आधुनिक रुपमा आर्थक विकाससम्बन्धी कार्यरू प्रारम्भ भएको हालै मात्र हो।',\n",
    "                   'हार धुनुहोस् र स्वास्थ जीवन जिउनुहोस्।',\n",
    "                   'जब प्रवीधिहरू एकीकृत हुन सूरु गर्छन् अर्थतन्त्र तथ सँस्कृति पनि निश्चितरूपमा विस्तारै एकीकृत हुने छ।',\n",
    "                   'उद्देयहरुमा पनि कुनै एक उद्देश्य पूर्ति नहुँदै अर्को नयाँ  उद्देश्यको रुपमा लिइने परम्परा बस्यो।',\n",
    "                   'लगानीकर्ताहरूको धयान तुरुन्त फेरियो , व्यापारीहरुले वताए ।',\n",
    "                    'अति धेरै हिज्जे गलती भएका शब्दहरू । तपाईँले टाइप गर्दा हिज्जे जाँच अक्षम पारयो ।',\n",
    "                    'लामो',\n",
    "                    'म नेपाली राम्रोसँग बोल्दिन',\n",
    "                    'तपाईंको उमर कति हो?',\n",
    "                    'मलाइ एक्लै छोडनुहोस्',\n",
    "                   'रुसी राष्ट्रपती पुटिनको प्रेम जावन त्य्ती सफल छैन ।']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57e9bb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_tokens(i,j):\n",
    "    s = sample_sentences[i].split()[:j]\n",
    "    return ' '.join(s)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2ff0980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['नेपालमा']\n",
      "[['नेपालमा', 'नेपालका', 'नेपालमै', 'नेपालीमा', 'नेपालकी']]\n",
      "['नेपालमा', 'आधुनिक']\n",
      "[['आधुनिक']]\n",
      "['नेपालमा', 'आधुनिक', 'रुपमा']\n",
      "[['रुपमा', 'रूपमा', 'रुटमा', 'रुपमै', 'रूपमै']]\n",
      "Sentence tensor: tensor([[ 120],\n",
      "        [1231]], device='cuda:0')\n",
      "tensor([   53,    84, 10144,  6402,  5712])\n",
      "['रूपमा', 'रुपमा', 'रूपमै', 'रुपमै', 'रुटमा']\n",
      "{'रुपमा': -1.5, 'रूपमा': 1.0, 'रुटमा': -1.5, 'रुपमै': -1.5, 'रूपमै': 1.0}\n",
      "Prod: रुपमा -3.015731938220757\n",
      "Prod: रूपमा -3.6714923063196574\n",
      "Prod: रुटमा -8.787374025981673\n",
      "Prod: रुपमै -5.626351139536203\n",
      "Prod: रूपमै -6.282111507635103\n",
      "[['रुपमा', 'रूपमा', 'रुटमा', 'रुपमै', 'रूपमै']] [tensor(-12.3442, grad_fn=<AddBackward0>), tensor(-10.2163, grad_fn=<AddBackward0>), tensor(-23.0686, grad_fn=<AddBackward0>), tensor(-18.3004, grad_fn=<AddBackward0>), tensor(-15.3290, grad_fn=<AddBackward0>)] ['रूपमा', 'रुपमा', 'रूपमै', 'रुपमै', 'रुटमा']\n",
      "['नेपालमा', 'आधुनिक', 'रुपमा', 'आर्थक']\n",
      "[['आर्थक', 'आर्थिक', 'अर्थ', 'दर्शक', 'आर्जन']]\n",
      "Sentence tensor: tensor([[ 120],\n",
      "        [1231],\n",
      "        [  53]], device='cuda:0')\n",
      "tensor([80137,    81,   496,  2927,  2379])\n",
      "['आर्थिक', 'आर्जन', 'दर्शक', 'अर्थ', 'आर्थक']\n",
      "{'आर्थक': -1.5, 'आर्थिक': 1.0, 'अर्थ': 1.0, 'दर्शक': 1.0, 'आर्जन': 1.0}\n",
      "Prod: आर्थक -3.015731938220757\n",
      "Prod: आर्थिक -5.802189538430683\n",
      "Prod: अर्थ -8.13750006148295\n",
      "Prod: दर्शक -14.37672648010204\n",
      "Prod: आर्जन -9.583155691243611\n",
      "[['आर्थक', 'आर्थिक', 'अर्थ', 'दर्शक', 'आर्जन']] [tensor(-25.3544, grad_fn=<AddBackward0>), tensor(-12.3458, grad_fn=<AddBackward0>), tensor(-20.1578, grad_fn=<AddBackward0>), tensor(-25.6007, grad_fn=<AddBackward0>), tensor(-17.3223, grad_fn=<AddBackward0>)] ['आर्थिक', 'आर्जन', 'अर्थ', 'आर्थक', 'दर्शक']\n",
      "['नेपालमा', 'आधुनिक', 'रुपमा', 'आर्थक', 'विकाससम्बन्धी']\n",
      "[['विकाससम्बन्धी']]\n",
      "['नेपालमा', 'आधुनिक', 'रुपमा', 'आर्थक', 'विकाससम्बन्धी', 'कार्यरू']\n",
      "[['कार्यरू', 'कार्यका', 'कार्यको', 'कार्यमा', 'कार्यले']]\n",
      "Sentence tensor: tensor([[  120],\n",
      "        [ 1231],\n",
      "        [   53],\n",
      "        [80137],\n",
      "        [28622]], device='cuda:0')\n",
      "tensor([   0, 6982, 3585, 1452, 6235])\n",
      "['कार्यको', 'कार्यले', 'कार्यका', 'कार्यमा', 'कार्यरू']\n",
      "{'कार्यरू': -1.5, 'कार्यका': 1.0, 'कार्यको': 1.0, 'कार्यमा': 1.0, 'कार्यले': 1.0}\n",
      "Prod: कार्यरू -2.689209034493467\n",
      "Prod: कार्यका -13.216144068763924\n",
      "Prod: कार्यको -10.715638119221188\n",
      "Prod: कार्यमा -13.654518910960887\n",
      "Prod: कार्यले -11.459140654440708\n",
      "[['कार्यरू', 'कार्यका', 'कार्यको', 'कार्यमा', 'कार्यले']] [tensor(-32.8140, grad_fn=<AddBackward0>), tensor(-23.8271, grad_fn=<AddBackward0>), tensor(-18.0305, grad_fn=<AddBackward0>), tensor(-24.4791, grad_fn=<AddBackward0>), tensor(-20.9388, grad_fn=<AddBackward0>)] ['कार्यको', 'कार्यले', 'कार्यका', 'कार्यमा', 'कार्यरू']\n",
      "['नेपालमा', 'आधुनिक', 'रुपमा', 'आर्थक', 'विकाससम्बन्धी', 'कार्यरू', 'प्रारम्भ']\n",
      "[['प्रारम्भ', 'प्रारम्भिक']]\n",
      "Sentence tensor: tensor([[  120],\n",
      "        [ 1231],\n",
      "        [   53],\n",
      "        [80137],\n",
      "        [28622],\n",
      "        [    0]], device='cuda:0')\n",
      "tensor([3096, 1613])\n",
      "['प्रारम्भ', 'प्रारम्भिक']\n",
      "{'प्रारम्भ': 1.0, 'प्रारम्भिक': 1.0}\n",
      "Prod: प्रारम्भ -2.560639685017959\n",
      "Prod: प्रारम्भिक -9.32752429785918\n",
      "[['प्रारम्भ', 'प्रारम्भिक']] [tensor(-10.6107, grad_fn=<AddBackward0>), tensor(-19.4400, grad_fn=<AddBackward0>)] ['प्रारम्भ', 'प्रारम्भिक']\n",
      "['नेपालमा', 'आधुनिक', 'रुपमा', 'आर्थक', 'विकाससम्बन्धी', 'कार्यरू', 'प्रारम्भ', 'भएको']\n",
      "[['भएको', 'भएका', 'भएकी', 'आएको', 'गएको']]\n",
      "Sentence tensor: tensor([[  120],\n",
      "        [ 1231],\n",
      "        [   53],\n",
      "        [80137],\n",
      "        [28622],\n",
      "        [    0],\n",
      "        [ 3096]], device='cuda:0')\n",
      "tensor([   6,   40, 1508,   66,  162])\n",
      "['भएको', 'भएका', 'आएको', 'भएकी', 'गएको']\n",
      "{'भएको': 1.0, 'भएका': 1.0, 'भएकी': 1.0, 'आएको': 1.0, 'गएको': 1.0}\n",
      "Prod: भएको -3.233888198770077\n",
      "Prod: भएका -4.121439894592966\n",
      "Prod: भएकी -7.116505279159252\n",
      "Prod: आएको -10.83479065831216\n",
      "Prod: गएको -5.965003672803284\n",
      "[['भएको', 'भएका', 'भएकी', 'आएको', 'गएको']] [tensor(-3.7068, grad_fn=<AddBackward0>), tensor(-9.2294, grad_fn=<AddBackward0>), tensor(-16.7425, grad_fn=<AddBackward0>), tensor(-19.5187, grad_fn=<AddBackward0>), tensor(-17.2672, grad_fn=<AddBackward0>)] ['भएको', 'भएका', 'भएकी', 'गएको', 'आएको']\n",
      "['नेपालमा', 'आधुनिक', 'रुपमा', 'आर्थक', 'विकाससम्बन्धी', 'कार्यरू', 'प्रारम्भ', 'भएको', 'हालै']\n",
      "[['हालै', 'भलै', 'हाल', 'कामै', 'काल']]\n",
      "Sentence tensor: tensor([[  120],\n",
      "        [ 1231],\n",
      "        [   53],\n",
      "        [80137],\n",
      "        [28622],\n",
      "        [    0],\n",
      "        [ 3096],\n",
      "        [    6]], device='cuda:0')\n",
      "tensor([ 1512, 10126,   371,  9580,  6983])\n",
      "['हालै', 'हाल', 'काल', 'भलै', 'कामै']\n",
      "{'हालै': 1.0, 'भलै': -1.5, 'हाल': 1.0, 'कामै': 1.0, 'काल': 1.0}\n",
      "Prod: हालै -3.233888198770077\n",
      "Prod: भलै -15.731279732335729\n",
      "Prod: हाल -5.2160702895501245\n",
      "Prod: कामै -9.102692945180824\n",
      "Prod: काल -8.30301955191165\n",
      "[['हालै', 'भलै', 'हाल', 'कामै', 'काल']] [tensor(-15.7770, grad_fn=<AddBackward0>), tensor(-33.6161, grad_fn=<AddBackward0>), tensor(-17.7840, grad_fn=<AddBackward0>), tensor(-26.8602, grad_fn=<AddBackward0>), tensor(-21.6649, grad_fn=<AddBackward0>)] ['हालै', 'हाल', 'काल', 'कामै', 'भलै']\n",
      "['नेपालमा', 'आधुनिक', 'रुपमा', 'आर्थक', 'विकाससम्बन्धी', 'कार्यरू', 'प्रारम्भ', 'भएको', 'हालै', 'मात्र']\n",
      "[['मात्र', 'मात्रा', 'जात्रा', 'नत्र', 'पत्र']]\n",
      "Sentence tensor: tensor([[  120],\n",
      "        [ 1231],\n",
      "        [   53],\n",
      "        [80137],\n",
      "        [28622],\n",
      "        [    0],\n",
      "        [ 3096],\n",
      "        [    6],\n",
      "        [ 1512]], device='cuda:0')\n",
      "tensor([  43, 1700, 6241, 3375,  877])\n",
      "['मात्र', 'पत्र', 'जात्रा', 'नत्र', 'मात्रा']\n",
      "{'मात्र': 1.0, 'मात्रा': 1.0, 'जात्रा': 1.0, 'नत्र': 1.0, 'पत्र': 1.0}\n",
      "Prod: मात्र -3.015731938220757\n",
      "Prod: मात्रा -4.964815520069482\n",
      "Prod: जात्रा -8.485977502907389\n",
      "Prod: नत्र -10.775306009405245\n",
      "Prod: पत्र -11.297495391821553\n",
      "[['मात्र', 'मात्रा', 'जात्रा', 'नत्र', 'पत्र']] [tensor(-7.6586, grad_fn=<AddBackward0>), tensor(-23.8158, grad_fn=<AddBackward0>), tensor(-20.3109, grad_fn=<AddBackward0>), tensor(-27.1882, grad_fn=<AddBackward0>), tensor(-21.5311, grad_fn=<AddBackward0>)] ['मात्र', 'जात्रा', 'पत्र', 'मात्रा', 'नत्र']\n",
      "['नेपालमा', 'आधुनिक', 'रुपमा', 'आर्थक', 'विकाससम्बन्धी', 'कार्यरू', 'प्रारम्भ', 'भएको', 'हालै', 'मात्र', 'हो']\n",
      "[['हो', 'को', 'जो', 'नो', 'पो']]\n",
      "Sentence tensor: tensor([[  120],\n",
      "        [ 1231],\n",
      "        [   53],\n",
      "        [80137],\n",
      "        [28622],\n",
      "        [    0],\n",
      "        [ 3096],\n",
      "        [    6],\n",
      "        [ 1512],\n",
      "        [   43]], device='cuda:0')\n",
      "tensor([   8,   32,  492, 8148, 1644])\n",
      "['हो', 'को', 'नो', 'जो', 'पो']\n",
      "{'हो': 1.0, 'को': 1.0, 'जो': 1.0, 'नो': 1.0, 'पो': 1.0}\n",
      "Prod: हो -3.9170355472516887\n",
      "Prod: को -7.003984809613215\n",
      "Prod: जो -8.844725665881539\n",
      "Prod: नो -8.628837285448501\n",
      "Prod: पो -7.654094478493177\n",
      "[['हो', 'को', 'जो', 'नो', 'पो']] [tensor(-10.2536, grad_fn=<AddBackward0>), tensor(-17.3159, grad_fn=<AddBackward0>), tensor(-20.5526, grad_fn=<AddBackward0>), tensor(-19.6657, grad_fn=<AddBackward0>), tensor(-23.1637, grad_fn=<AddBackward0>)] ['हो', 'को', 'नो', 'जो', 'पो']\n",
      "['नेपालमा', 'आधुनिक', 'रुपमा', 'आर्थक', 'विकाससम्बन्धी', 'कार्यरू', 'प्रारम्भ', 'भएको', 'हालै', 'मात्र', 'हो', '।']\n",
      "[['।', 'ः', 'अ', 'आ', 'इ']]\n",
      "Sentence tensor: tensor([[  120],\n",
      "        [ 1231],\n",
      "        [   53],\n",
      "        [80137],\n",
      "        [28622],\n",
      "        [    0],\n",
      "        [ 3096],\n",
      "        [    6],\n",
      "        [ 1512],\n",
      "        [   43],\n",
      "        [    8]], device='cuda:0')\n",
      "tensor([   1, 3044, 5528, 5110, 8290])\n",
      "['।', 'ः', 'इ', 'अ', 'आ']\n",
      "{'।': -1.5, 'ः': -1.5, 'अ': 1.0, 'आ': 1.0, 'इ': 1.0}\n",
      "Prod: । -4.605170185988091\n",
      "Prod: ः -12.206072645530172\n",
      "Prod: अ -12.206072645530172\n",
      "Prod: आ -12.206072645530172\n",
      "Prod: इ -12.206072645530172\n",
      "[['।', 'ः', 'अ', 'आ', 'इ']] [tensor(-6.2559, grad_fn=<AddBackward0>), tensor(-23.3136, grad_fn=<AddBackward0>), tensor(-25.1756, grad_fn=<AddBackward0>), tensor(-28.1127, grad_fn=<AddBackward0>), tensor(-24.1800, grad_fn=<AddBackward0>)] ['।', 'ः', 'इ', 'अ', 'आ']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['नेपालमा', 'नेपालका', 'नेपालमै', 'नेपालीमा', 'नेपालकी'],\n",
       " ['आधुनिक'],\n",
       " ['रूपमा', 'रुपमा', 'रूपमै', 'रुपमै', 'रुटमा'],\n",
       " ['आर्थिक', 'आर्जन', 'अर्थ', 'आर्थक', 'दर्शक'],\n",
       " ['विकाससम्बन्धी'],\n",
       " ['कार्यको', 'कार्यले', 'कार्यका', 'कार्यमा', 'कार्यरू'],\n",
       " ['प्रारम्भ', 'प्रारम्भिक'],\n",
       " ['भएको', 'भएका', 'भएकी', 'गएको', 'आएको'],\n",
       " ['हालै', 'हाल', 'काल', 'कामै', 'भलै'],\n",
       " ['मात्र', 'जात्रा', 'पत्र', 'मात्रा', 'नत्र'],\n",
       " ['हो', 'को', 'नो', 'जो', 'पो'],\n",
       " ['।', 'ः', 'इ', 'अ', 'आ']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_choices_word(sample_sentences[3],model = model,p_lambda = 1.2,l_lambda = 1,trie = True,likelihood = 'bm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f469b436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['रुसी']\n",
      "[['रुसी', 'रूसी', 'रुस', 'एसी', 'केसी']]\n",
      "['रुसी', 'राष्ट्रपती']\n",
      "[['राष्ट्रपति', 'राष्ट्रपती']]\n",
      "Sentence tensor: tensor([[6721]], device='cuda:0')\n",
      "tensor([  387, 38109])\n",
      "['राष्ट्रपति', 'राष्ट्रपती']\n",
      "{'राष्ट्रपति': 1.0, 'राष्ट्रपती': -1.5}\n",
      "Prod: राष्ट्रपति -3.474170740713985\n",
      "Prod: राष्ट्रपती -2.3473949765927884\n",
      "[['राष्ट्रपति', 'राष्ट्रपती']] [tensor(-4.6404, grad_fn=<AddBackward0>), tensor(-17.1087, grad_fn=<AddBackward0>)] [('राष्ट्रपति', tensor(-4.6404, grad_fn=<AddBackward0>)), ('राष्ट्रपती', tensor(-17.1087, grad_fn=<AddBackward0>))]\n",
      "['रुसी', 'राष्ट्रपति', 'पुटिनको']\n",
      "[['पुरिएको', 'पुलिसको', 'पुटिनको']]\n",
      "Sentence tensor: tensor([[6721],\n",
      "        [ 387]], device='cuda:0')\n",
      "tensor([13501, 28242, 53975])\n",
      "['पुटिनको', 'पुलिसको', 'पुरिएको']\n",
      "{'पुरिएको': 1.0, 'पुलिसको': 1.0, 'पुटिनको': -1.5}\n",
      "Prod: पुरिएको -14.338266673788276\n",
      "Prod: पुलिसको -9.061679608889106\n",
      "Prod: पुटिनको -2.689209034493467\n",
      "[['पुरिएको', 'पुलिसको', 'पुटिनको']] [tensor(-33.9869, grad_fn=<AddBackward0>), tensor(-27.8732, grad_fn=<AddBackward0>), tensor(-11.2383, grad_fn=<AddBackward0>)] [('पुटिनको', tensor(-11.2383, grad_fn=<AddBackward0>)), ('पुलिसको', tensor(-27.8732, grad_fn=<AddBackward0>)), ('पुरिएको', tensor(-33.9869, grad_fn=<AddBackward0>))]\n",
      "['रुसी', 'राष्ट्रपति', 'पुटिनको', 'प्रेम']\n",
      "[['प्रेम', 'परेमा', 'प्रम', 'प्रेमी', 'प्रेस']]\n",
      "Sentence tensor: tensor([[ 6721],\n",
      "        [  387],\n",
      "        [53975]], device='cuda:0')\n",
      "tensor([ 672, 6143, 5591, 5698, 1167])\n",
      "['प्रेम', 'प्रेस', 'प्रेमी', 'प्रम', 'परेमा']\n",
      "{'प्रेम': 1.0, 'परेमा': 1.0, 'प्रम': 1.0, 'प्रेमी': 1.0, 'प्रेस': 1.0}\n",
      "Prod: प्रेम -3.015731938220757\n",
      "Prod: परेमा -4.943538603008278\n",
      "Prod: प्रम -3.952730684505904\n",
      "Prod: प्रेमी -5.341080602852699\n",
      "Prod: प्रेस -5.482918991490519\n",
      "[['प्रेम', 'परेमा', 'प्रम', 'प्रेमी', 'प्रेस']] [tensor(-10.7588, grad_fn=<AddBackward0>), tensor(-22.4016, grad_fn=<AddBackward0>), tensor(-21.1829, grad_fn=<AddBackward0>), tensor(-17.2985, grad_fn=<AddBackward0>), tensor(-16.4656, grad_fn=<AddBackward0>)] [('प्रेम', tensor(-10.7588, grad_fn=<AddBackward0>)), ('प्रेस', tensor(-16.4656, grad_fn=<AddBackward0>)), ('प्रेमी', tensor(-17.2985, grad_fn=<AddBackward0>)), ('प्रम', tensor(-21.1829, grad_fn=<AddBackward0>)), ('परेमा', tensor(-22.4016, grad_fn=<AddBackward0>))]\n",
      "['रुसी', 'राष्ट्रपति', 'पुटिनको', 'प्रेम', 'जावन']\n",
      "[['जवान', 'जावन', 'जडान', 'जापान', 'जिवन']]\n",
      "Sentence tensor: tensor([[ 6721],\n",
      "        [  387],\n",
      "        [53975],\n",
      "        [  672]], device='cuda:0')\n",
      "tensor([4122,    0, 1646, 1803, 7302])\n",
      "['जवान', 'जिवन', 'जापान', 'जडान', 'जावन']\n",
      "{'जवान': 1.0, 'जावन': -1.5, 'जडान': 1.0, 'जापान': 1.0, 'जिवन': -1.5}\n",
      "Prod: जवान -18.435693117854242\n",
      "Prod: जावन -3.233888198770077\n",
      "Prod: जडान -18.435693117854242\n",
      "Prod: जापान -15.993140285136931\n",
      "Prod: जिवन -6.901534786415757\n",
      "[['जवान', 'जावन', 'जडान', 'जापान', 'जिवन']] [tensor(-31.4971, grad_fn=<AddBackward0>), tensor(-33.6652, grad_fn=<AddBackward0>), tensor(-38.4753, grad_fn=<AddBackward0>), tensor(-30.6733, grad_fn=<AddBackward0>), tensor(-22.5989, grad_fn=<AddBackward0>)] [('जिवन', tensor(-22.5989, grad_fn=<AddBackward0>)), ('जापान', tensor(-30.6733, grad_fn=<AddBackward0>)), ('जवान', tensor(-31.4971, grad_fn=<AddBackward0>)), ('जावन', tensor(-33.6652, grad_fn=<AddBackward0>)), ('जडान', tensor(-38.4753, grad_fn=<AddBackward0>))]\n",
      "['रुसी', 'राष्ट्रपति', 'पुटिनको', 'प्रेम', 'जिवन', 'त्य्ती']\n",
      "[['त्य्ती', 'त्यति', 'त्यतै', 'त्यही', 'त्यस्ता']]\n",
      "Sentence tensor: tensor([[ 6721],\n",
      "        [  387],\n",
      "        [53975],\n",
      "        [  672],\n",
      "        [ 7302]], device='cuda:0')\n",
      "tensor([    0,   724, 12156,   309,  1040])\n",
      "['त्यति', 'त्यही', 'त्यतै', 'त्यस्ता', 'त्य्ती']\n",
      "{'त्य्ती': -1.5, 'त्यति': 1.0, 'त्यतै': 1.0, 'त्यही': 1.0, 'त्यस्ता': 1.0}\n",
      "Prod: त्य्ती -2.838389255823903\n",
      "Prod: त्यति -4.0959246123696245\n",
      "Prod: त्यतै -10.57005130779051\n",
      "Prod: त्यही -7.556486557940963\n",
      "Prod: त्यस्ता -11.446769168616823\n",
      "[['त्य्ती', 'त्यति', 'त्यतै', 'त्यही', 'त्यस्ता']] [tensor(-32.7425, grad_fn=<AddBackward0>), tensor(-15.4035, grad_fn=<AddBackward0>), tensor(-24.8089, grad_fn=<AddBackward0>), tensor(-18.9742, grad_fn=<AddBackward0>), tensor(-27.1429, grad_fn=<AddBackward0>)] [('त्यति', tensor(-15.4035, grad_fn=<AddBackward0>)), ('त्यही', tensor(-18.9742, grad_fn=<AddBackward0>)), ('त्यतै', tensor(-24.8089, grad_fn=<AddBackward0>)), ('त्यस्ता', tensor(-27.1429, grad_fn=<AddBackward0>)), ('त्य्ती', tensor(-32.7425, grad_fn=<AddBackward0>))]\n",
      "['रुसी', 'राष्ट्रपति', 'पुटिनको', 'प्रेम', 'जिवन', 'त्यति', 'सफल']\n",
      "[['सफल', 'असफल', 'फल', 'सफा', 'सबल']]\n",
      "Sentence tensor: tensor([[ 6721],\n",
      "        [  387],\n",
      "        [53975],\n",
      "        [  672],\n",
      "        [ 7302],\n",
      "        [  724]], device='cuda:0')\n",
      "tensor([ 239, 1808, 2375, 1535, 4376])\n",
      "['असफल', 'सफल', 'सबल', 'फल', 'सफा']\n",
      "{'सफल': 1.0, 'असफल': 1.0, 'फल': 1.0, 'सफा': 1.0, 'सबल': 1.0}\n",
      "Prod: सफल -3.516574563706637\n",
      "Prod: असफल -6.7890586355638325\n",
      "Prod: फल -6.51253936836271\n",
      "Prod: सफा -7.310264382172918\n",
      "Prod: सबल -11.11747702324872\n",
      "[['सफल', 'असफल', 'फल', 'सफा', 'सबल']] [tensor(-12.7553, grad_fn=<AddBackward0>), tensor(-15.6760, grad_fn=<AddBackward0>), tensor(-19.9256, grad_fn=<AddBackward0>), tensor(-20.7347, grad_fn=<AddBackward0>), tensor(-23.4480, grad_fn=<AddBackward0>)] [('सफल', tensor(-12.7553, grad_fn=<AddBackward0>)), ('असफल', tensor(-15.6760, grad_fn=<AddBackward0>)), ('फल', tensor(-19.9256, grad_fn=<AddBackward0>)), ('सफा', tensor(-20.7347, grad_fn=<AddBackward0>)), ('सबल', tensor(-23.4480, grad_fn=<AddBackward0>))]\n",
      "['रुसी', 'राष्ट्रपति', 'पुटिनको', 'प्रेम', 'जिवन', 'त्यति', 'सफल', 'छैन']\n",
      "[['छैन', 'छन', 'छिन', 'छैन्', 'हैन']]\n",
      "Sentence tensor: tensor([[ 6721],\n",
      "        [  387],\n",
      "        [53975],\n",
      "        [  672],\n",
      "        [ 7302],\n",
      "        [  724],\n",
      "        [  239]], device='cuda:0')\n",
      "tensor([  35,  348, 4334, 2612, 1247])\n",
      "['छैन', 'छैन्', 'हैन', 'छिन', 'छन']\n",
      "{'छैन': 1.0, 'छन': 1.0, 'छिन': 1.0, 'छैन्': -1.5, 'हैन': -1.5}\n",
      "Prod: छैन -3.516574563706637\n",
      "Prod: छन -4.125805881257084\n",
      "Prod: छिन -11.11747702324872\n",
      "Prod: छैन् -5.632466802586754\n",
      "Prod: हैन -4.895851352167881\n",
      "[['छैन', 'छन', 'छिन', 'छैन्', 'हैन']] [tensor(-6.5762, grad_fn=<AddBackward0>), tensor(-18.4115, grad_fn=<AddBackward0>), tensor(-24.8325, grad_fn=<AddBackward0>), tensor(-14.6704, grad_fn=<AddBackward0>), tensor(-16.3415, grad_fn=<AddBackward0>)] [('छैन', tensor(-6.5762, grad_fn=<AddBackward0>)), ('छैन्', tensor(-14.6704, grad_fn=<AddBackward0>)), ('हैन', tensor(-16.3415, grad_fn=<AddBackward0>)), ('छन', tensor(-18.4115, grad_fn=<AddBackward0>)), ('छिन', tensor(-24.8325, grad_fn=<AddBackward0>))]\n",
      "['रुसी', 'राष्ट्रपति', 'पुटिनको', 'प्रेम', 'जिवन', 'त्यति', 'सफल', 'छैन', '।']\n",
      "[['।', 'ः', 'अ', 'आ', 'इ']]\n",
      "Sentence tensor: tensor([[ 6721],\n",
      "        [  387],\n",
      "        [53975],\n",
      "        [  672],\n",
      "        [ 7302],\n",
      "        [  724],\n",
      "        [  239],\n",
      "        [   35]], device='cuda:0')\n",
      "tensor([   1, 3044, 5528, 5110, 8290])\n",
      "['।', 'ः', 'अ', 'इ', 'आ']\n",
      "{'।': -1.5, 'ः': -1.5, 'अ': 1.0, 'आ': 1.0, 'इ': 1.0}\n",
      "Prod: । -4.605170185988091\n",
      "Prod: ः -12.206072645530172\n",
      "Prod: अ -12.206072645530172\n",
      "Prod: आ -12.206072645530172\n",
      "Prod: इ -12.206072645530172\n",
      "[['।', 'ः', 'अ', 'आ', 'इ']] [tensor(-6.3779, grad_fn=<AddBackward0>), tensor(-25.3591, grad_fn=<AddBackward0>), tensor(-27.2690, grad_fn=<AddBackward0>), tensor(-28.0900, grad_fn=<AddBackward0>), tensor(-27.5270, grad_fn=<AddBackward0>)] [('।', tensor(-6.3779, grad_fn=<AddBackward0>)), ('ः', tensor(-25.3591, grad_fn=<AddBackward0>)), ('अ', tensor(-27.2690, grad_fn=<AddBackward0>)), ('इ', tensor(-27.5270, grad_fn=<AddBackward0>)), ('आ', tensor(-28.0900, grad_fn=<AddBackward0>))]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['रुसी', 'रूसी', 'रुस', 'एसी', 'केसी'],\n",
       " ['राष्ट्रपति'],\n",
       " ['पुटिनको'],\n",
       " ['प्रेम'],\n",
       " ['जिवन'],\n",
       " ['त्यति'],\n",
       " ['सफल'],\n",
       " ['छैन'],\n",
       " ['।']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autocorrect_word(sample_sentences[-1],model = model,p_lambda = 1.2,l_lambda = 1,trie = True,likelihood = 'bm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c549f13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['जब', 'प्रविधिहरू', 'एकीकृत', 'हुन', 'सूरु', 'गर्छन्', 'अर्थतन्त्र', 'तथा', 'सँस्कृति', 'पनि', 'निश्चितरूपमा']\n",
      "[['निश्चितरुपमा', 'निश्चितरूपमा']]\n",
      "Sentence tensor: tensor([[  680],\n",
      "        [44119],\n",
      "        [ 1350],\n",
      "        [   37],\n",
      "        [56618],\n",
      "        [  377],\n",
      "        [ 2651],\n",
      "        [   14],\n",
      "        [21666],\n",
      "        [    5]], device='cuda:0')\n",
      "tensor([ 88584, 122294])\n",
      "tensor([[[ -5.6213,  -6.1727,  -4.2060,  ..., -16.5473, -16.6862, -17.2982]],\n",
      "\n",
      "        [[ -3.8301,  -4.6486,  -3.1276,  ..., -17.2521, -15.2524, -19.2046]],\n",
      "\n",
      "        [[ -4.1067,  -6.2689,  -3.2926,  ..., -15.9814, -15.4236, -17.2361]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -4.3750, -10.2782,  -8.2561,  ..., -15.6630, -18.0608, -16.0671]],\n",
      "\n",
      "        [[ -5.2898,  -6.7618,  -4.0764,  ..., -17.2819, -15.3262, -16.6465]],\n",
      "\n",
      "        [[ -5.4032,  -3.9699,  -5.5404,  ..., -14.8377, -16.6672, -15.7660]]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>) torch.Size([10, 1, 342570]) 10\n",
      "tensor([-13.3704, -13.8763], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([ 88584, 122294])\n",
      "tensor([  6172, 129468, 123298,  ...,   1602,    134,    168], device='cuda:0')\n",
      "tensor([0, 1], device='cuda:0')\n",
      "जान्छु न्यूनीकरण दफा चाहन्छु\n",
      "['निश्चितरुपमा', 'निश्चितरूपमा']\n",
      "Prod: निश्चितरुपमा -2.2097452998770017\n",
      "Prod: निश्चितरूपमा -2.174938610048678\n",
      "[['निश्चितरुपमा', 'निश्चितरूपमा']] [tensor(-20.2543, grad_fn=<AddBackward0>), tensor(-20.8265, grad_fn=<AddBackward0>)] ['निश्चितरुपमा', 'निश्चितरूपमा']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['निश्चितरुपमा', 'निश्चितरूपमा']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_current_word('जब प्रविधिहरू एकीकृत हुन सूरु गर्छन् अर्थतन्त्र तथा सँस्कृति पनि निश्चितरूपमा',model=model,p_lambda = 1.2,l_lambda = 1,trie = True,likelihood = 'bm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2202044a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_sentences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "742f5a21",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[39, -1]' is invalid for input of size 33",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtransformer_probab_final_word\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_sentences\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\SpellChecker\\transformer.py:424\u001b[0m, in \u001b[0;36mtransformer_probab_final_word\u001b[1;34m(sentence_list, candidates, device)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransformer_probab_final_word\u001b[39m(sentence_list, candidates\u001b[38;5;241m=\u001b[39m[], device \u001b[38;5;241m=\u001b[39m device):\n\u001b[1;32m--> 424\u001b[0m     sentence_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSentence tensor:\u001b[39m\u001b[38;5;124m\"\u001b[39m,sentence_tensor)\n\u001b[0;32m    427\u001b[0m     candidate_sti \u001b[38;5;241m=\u001b[39m preprocess_list([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(candidates[\u001b[38;5;241m0\u001b[39m])])\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mF:\\SpellChecker\\transformer.py:408\u001b[0m, in \u001b[0;36mpreprocess_list\u001b[1;34m(sentences, device)\u001b[0m\n\u001b[0;32m    406\u001b[0m     length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(sentences)\n\u001b[0;32m    407\u001b[0m \u001b[38;5;66;03m#     st_i = torch.stack([data_process(sent) for sent in sentences]).to(device) \u001b[39;00m\n\u001b[1;32m--> 408\u001b[0m     st_i \u001b[38;5;241m=\u001b[39m \u001b[43mdata_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m    409\u001b[0m \u001b[38;5;66;03m#     st_i = st_i.squeeze(0)   \u001b[39;00m\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m st_i\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[39, -1]' is invalid for input of size 33"
     ]
    }
   ],
   "source": [
    "transformer_probab_final_word(sample_sentences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f1ee07",
   "metadata": {},
   "outputs": [],
   "source": [
    "correctize_with_window_nn(sample_sentences[2],model=model,p_lambda = 0.8,trie = True,likelihood = 'bm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e080c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "correctize_with_window_nn_(sample_sentences[2],model=model,p_lambda = 0.8,trie = True,likelihood = 'bm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9447501",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc,wp = return_choices2(sample_sentences[4],model=model,p_lambda = 1.5,trie = True,likelihood = 'bm',model_type = 'transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7f9a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_choices(sample_sentences[-1],model=model,p_lambda = 1.5,trie = True,likelihood = 'bm',model_type = 'transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530afca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a41ed5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc,wp = return_choices2(sample_sentences[1],model=model,p_lambda = 1.5,trie = True,likelihood = 'bm',model_type = 'transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ae8592",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f92757",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(wc,wp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eef0006",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0410dad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_choices(a,model=model,p_lambda = 1.5,trie = True,likelihood = 'bm',model_type = 'transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660ff89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitution based "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "999a340f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'तिमीलै कता जाना मन छ ?'\n",
    "b = 'आज मा स्कुल जादिन'\n",
    "c = 'तिमि यता आऊ त !'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fe086a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentences = ['हरेक सेपालीले नेपामको संविधानक पालना गर्नुपर्छ ।' ,\n",
    "                    'म पुस्तकलयबाटे थुलो किताब पढ्न चाहन्छ ।',\n",
    "                    'तर उस समयमा पनि स्वस्थ राजनैतिक वातावरणको अभावले गर्दा देश विकासतर्फ विशेष प्रगति हुन  सकेन।',\n",
    "                   'नेपालमा आधुनिक रुपमा आर्थक विकाससम्बन्धी कार्यरू प्रारम्भ भएको हालै मात्र हो।',\n",
    "                   'हार धुनुहोस् र स्वास्थ जीवन जिउनुहोस्।',\n",
    "                   'जब प्रवीधिहरू एकीकृत हुन सूरु गर्छन् अर्थतन्त्र तथ सँस्कृति पनि निश्चितरूपमा विस्तारै एकीकृत हुने छ।',\n",
    "                   'उद्देयहरुमा पनि कुनै एक उद्देश्य पूर्ति नहुँदै अर्को नयाँ  उद्देश्यको रुपमा लिइने परम्परा बस्यो।',\n",
    "                   'लगानीकर्ताहरूको धयान तुरुन्त फेरियो , व्यापारीहरूले वताए ।',\n",
    "                    'अति धेरै हिज्जे गलती भएका शब्दहरू । तपाईँले टाइप गर्दा हिज्जे जाँच अक्षम पारयो ।',\n",
    "                    'लामो',\n",
    "                    'म नेपाली राम्रोसँग बोल्दिन',\n",
    "                    'तपाईंको उमर कति हो?',\n",
    "                    'मलाइ एक्लै छोडनुहोस्',\n",
    "                    c,\n",
    "                    b,\n",
    "                    a\n",
    "                    \n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d35172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8e77409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of candidates: 125\n",
      "In candidate_probabilities...\n",
      "2\n",
      "Done...\n",
      "Length of candidates: 250\n",
      "In candidate_probabilities...\n",
      "4\n",
      "Done...\n",
      "Length of candidates: 625\n",
      "In candidate_probabilities...\n",
      "10\n",
      "Done...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['नेपालमा', 'नेपालीमा'],\n",
       " ['आधुनिक'],\n",
       " ['रूपमा', 'रुपमा', 'रूपमै', 'रुपमै'],\n",
       " ['आर्थिक', 'अर्थ'],\n",
       " ['विकाससम्बन्धी'],\n",
       " ['कार्यको', 'कार्यरू', 'कार्यले', 'कार्यमा'],\n",
       " ['प्रारम्भ'],\n",
       " ['भएको', 'भएका'],\n",
       " ['हालै', 'हाल', 'काल', 'कामै', 'भलै'],\n",
       " ['मात्र', 'मात्रा', 'जात्रा'],\n",
       " ['हो'],\n",
       " ['।']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_choices(sample_sentences[3],model=model,p_lambda = 0.8,trie = True,likelihood = 'bm',model_type = 'transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5dc6ec63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['म पुस्तकालयबाट ठुलो किताब पढ्न']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[' '.join(('म', 'पुस्तकालयबाट', 'ठुलो', 'किताब', 'पढ्न'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "324afa4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-142.8868, -143.8868])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flip(torch.tensor([torch.tensor(-143.8868),torch.tensor(-142.8868)]),dims = (0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39352bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limitation of transformer model : Less candidate sentences are genereated due to Computational issues"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
